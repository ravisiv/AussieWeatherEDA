{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1746415f",
   "metadata": {},
   "source": [
    "# Mini Lab : Logistic Regression and Support Vector Machine\n",
    "\n",
    "### Group 3 - Members:\n",
    "\n",
    "_Apurv Mittal_<br>\n",
    "_Seemant Srivastava_<br>\n",
    "_Ravi Sivaraman_<br>\n",
    "_Tai Chowdhury_<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e576f7",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791cd903",
   "metadata": {},
   "source": [
    "As discussed in Lab 1, we have acquired the Australian Weather dataset from Kaggle portal. It contains 10 years of weather data collected from many locations across Australia. These are daily weather observations. There are 145,459 observations with 23 attributes in the original dataset. \n",
    "\n",
    "We have chosen RainTomorrow (categorical) and Rainfall (continuous) as predictor variables. RainTomorrow is a categorical attribute which indicates whether it is going to rain tomorrow - yes or no. Rainfall is a continuous attribute that measures amount of rainfall each of the particular locations have received (in mm). Using our models, we will be able to design an algorithm where the bureau can help to predict rainfall for different regions in Australia.\n",
    "\n",
    "In this Lab 2 assignment, we have measured the accuracy and effectiveness of our model for categorical variable RainTomorrow by using 10-fold cross validation against the confusion matrix measurements like: Precision, Recall and Accuracy. We have explored the methods of logistic regression and support vector machine (SVM) models on our dataset. \n",
    "\n",
    "We have used `scikit-learn` packages for our exploration. We ran logistic regression models with all the available solvers in the `scikit-learn` package and compare the effictiveness and accuracy of the model to predict `RainfallTomorrow`. We also measured the duration of model run from each models to compare model performance and efficiency as well.\n",
    " \n",
    "To get started, we will start with loading all the necessary packages for our analysis. We will start our analysis with `df_impute` which is the imputed dataframe from our last explanatory data analysis Lab 1 project. Using this dataframe will ensure data consistency for all the labs going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a96353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from shapely.geometry import Point\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce8247b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore Warnings on final\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "888e9335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Imputed Australia weather data\n",
    "df_impute = pd.read_csv(\"weatherAUS_imputed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a61b1c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.032209</td>\n",
       "      <td>8.890686</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WNW</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.684394</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.032209</td>\n",
       "      <td>8.890686</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>WSW</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>3.635105</td>\n",
       "      <td>3.684394</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.032209</td>\n",
       "      <td>8.890686</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WSW</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>3.635105</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.032209</td>\n",
       "      <td>8.890686</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>E</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>3.635105</td>\n",
       "      <td>3.684394</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.032209</td>\n",
       "      <td>8.890686</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>NW</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine WindGustDir  \\\n",
       "0     13.4     22.9       0.6     6.032209  8.890686           W   \n",
       "1      7.4     25.1       0.0     6.032209  8.890686         WNW   \n",
       "2     12.9     25.7       0.0     6.032209  8.890686         WSW   \n",
       "3      9.2     28.0       0.0     6.032209  8.890686          NE   \n",
       "4     17.5     32.3       1.0     6.032209  8.890686           W   \n",
       "\n",
       "   WindGustSpeed WindDir9am WindDir3pm  WindSpeed9am  ...  Humidity9am  \\\n",
       "0           44.0          W        WNW          20.0  ...         71.0   \n",
       "1           44.0        NNW        WSW           4.0  ...         44.0   \n",
       "2           46.0          W        WSW          19.0  ...         38.0   \n",
       "3           24.0         SE          E          11.0  ...         45.0   \n",
       "4           41.0        ENE         NW           7.0  ...         82.0   \n",
       "\n",
       "   Humidity3pm  Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  \\\n",
       "0         22.0       1007.7       1007.1  8.000000  3.684394     16.9   \n",
       "1         25.0       1010.6       1007.8  3.635105  3.684394     17.2   \n",
       "2         30.0       1007.6       1008.7  3.635105  2.000000     21.0   \n",
       "3         16.0       1017.6       1012.8  3.635105  3.684394     18.1   \n",
       "4         33.0       1010.8       1006.0  7.000000  8.000000     17.8   \n",
       "\n",
       "   Temp3pm  RainToday RainTomorrow  \n",
       "0     21.8         No           No  \n",
       "1     24.3         No           No  \n",
       "2     23.2         No           No  \n",
       "3     26.5         No           No  \n",
       "4     29.7         No           No  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  View the top rows of the data imported\n",
    "df_impute.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9fb065",
   "metadata": {},
   "source": [
    "The imputed data doesn't include any null or missing values. Also, we have dropped the columns like: Date of observation and City Name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb585c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Variables: Index(['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine',\n",
      "       'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n",
      "       'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm',\n",
      "       'Temp9am', 'Temp3pm'],\n",
      "      dtype='object')\n",
      "Categorical Variables: Index(['WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_impute_num = df_impute.columns[df_impute.dtypes == 'float64']\n",
    "df_impute_cat=df_impute.columns[df_impute.dtypes == 'object']\n",
    "print(\"Numeric Variables:\", df_impute_num)\n",
    "print(\"Categorical Variables:\", df_impute_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f6fa55",
   "metadata": {},
   "source": [
    "Before continuing further, we need to check which variables are numeric and which are not. As the models expect numerical variables. We will filter and identify non-numeric variables.\n",
    "\n",
    "`WindGustDir`, `WindDir9am`, `WindDir3pm`, `RainToday` and `RainTomorrow`are not numeric. Here `RainTomorrow` is our response variable. we handle the other variables with hot-one-encoding later in the flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9e3c17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep the original data\n",
    "df_model = df_impute.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a635ed8",
   "metadata": {},
   "source": [
    "Creating a new DataFrame `df_model` for modeling to avoid any changes to the original dataset `df_impute`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1364fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new variable to Identify if it RainToday\n",
    "\n",
    "df_model[\"IsRainToday\"] = df_impute['RainToday']\n",
    "\n",
    "# Replacing No with 0 and Yes with 1.\n",
    "\n",
    "df_model['IsRainToday'].replace({'No': 0, 'Yes': 1},inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e0a055",
   "metadata": {},
   "source": [
    "Assigning `0` to No values and `1` to Yes values in `RainToday` (Changed to `IsRainToday`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d044fa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_impute (140787, 21)\n",
      "df_model (140787, 22)\n"
     ]
    }
   ],
   "source": [
    "print(\"df_impute\", df_impute.shape)\n",
    "print(\"df_model\", df_model.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f62e7979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "      <th>IsRainToday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.032209</td>\n",
       "      <td>8.890686</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WNW</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.684394</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.032209</td>\n",
       "      <td>8.890686</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>WSW</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>3.635105</td>\n",
       "      <td>3.684394</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.032209</td>\n",
       "      <td>8.890686</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WSW</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>3.635105</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.032209</td>\n",
       "      <td>8.890686</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>E</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>3.635105</td>\n",
       "      <td>3.684394</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.032209</td>\n",
       "      <td>8.890686</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>NW</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine WindGustDir  \\\n",
       "0     13.4     22.9       0.6     6.032209  8.890686           W   \n",
       "1      7.4     25.1       0.0     6.032209  8.890686         WNW   \n",
       "2     12.9     25.7       0.0     6.032209  8.890686         WSW   \n",
       "3      9.2     28.0       0.0     6.032209  8.890686          NE   \n",
       "4     17.5     32.3       1.0     6.032209  8.890686           W   \n",
       "\n",
       "   WindGustSpeed WindDir9am WindDir3pm  WindSpeed9am  ...  Humidity3pm  \\\n",
       "0           44.0          W        WNW          20.0  ...         22.0   \n",
       "1           44.0        NNW        WSW           4.0  ...         25.0   \n",
       "2           46.0          W        WSW          19.0  ...         30.0   \n",
       "3           24.0         SE          E          11.0  ...         16.0   \n",
       "4           41.0        ENE         NW           7.0  ...         33.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1007.7       1007.1  8.000000  3.684394     16.9     21.8         No   \n",
       "1       1010.6       1007.8  3.635105  3.684394     17.2     24.3         No   \n",
       "2       1007.6       1008.7  3.635105  2.000000     21.0     23.2         No   \n",
       "3       1017.6       1012.8  3.635105  3.684394     18.1     26.5         No   \n",
       "4       1010.8       1006.0  7.000000  8.000000     17.8     29.7         No   \n",
       "\n",
       "   RainTomorrow IsRainToday  \n",
       "0            No           0  \n",
       "1            No           0  \n",
       "2            No           0  \n",
       "3            No           0  \n",
       "4            No           0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the values to check if the data looks good\n",
    "\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a25167",
   "metadata": {},
   "source": [
    "We can observe that the presence of “0” and “1” is almost in the 78:22 ratio. So there is a class imbalance and we have to deal with it. To fight against the class imbalance, we will use here the oversampling of the minority class. Since the size of the dataset is quite small, majority class subsampling wouldn’t make much sense here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f90fc0",
   "metadata": {},
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe083dc",
   "metadata": {},
   "source": [
    "Before we create our models, we need to format our attributes. We are converting `RainToday` and `RainTomorrow` into numeric variables to `0` and `1`. We also decided to go ahead with one-hot-encoding `WindGustDir`, `WindDir9am`, and `WindDir3pm` attributes based on the direction of the wind. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad32c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one-hot encoding using dummies\n",
    "\n",
    "gust_df = pd.get_dummies(df_model.WindGustDir,prefix='GustDir')\n",
    "wind3pm_df = pd.get_dummies(df_model.WindDir3pm,prefix='Wind3pm')\n",
    "wind9am_df = pd.get_dummies(df_model.WindDir9am,prefix='Wind9am')\n",
    "df_model = pd.concat((df_model,gust_df, wind3pm_df, wind9am_df),axis=1) # add back into the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc00c0e",
   "metadata": {},
   "source": [
    "We decided to do one-hot-encoding using dummies function as machine learning algorithms and models requires numerical values for both input and output attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "404f163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop categorical columns\n",
    "\n",
    "df_model = df_model.drop(['WindDir3pm', 'WindDir9am', 'WindGustDir', 'RainToday'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b973430",
   "metadata": {},
   "source": [
    "After conversions, we are removing these categorical attributes to avoid duplicates as we have those data in numerical format. We are added the newly formatted attributes and rest of the continuous attributes into a new dataframe - df_model. We will use the new dataframe for modeling.\n",
    "\n",
    "Reference: https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "782dd623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there 1's and 0's in the RainToday column? True\n"
     ]
    }
   ],
   "source": [
    "#Check if Yes is replaced as 1\n",
    "\n",
    "print(\"Are there 1's and 0's in the RainToday column?\", \n",
    "      (df_model['IsRainToday'].sum() > 0) and (df_model['IsRainToday'].sum() < len(df_model['IsRainToday'])))\n",
    "\n",
    "#Non zero output means there is a mixture of 1's and 0's\n",
    "#if sum is less"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b634fff9",
   "metadata": {},
   "source": [
    "Checking if the data imputation happened accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49b2e073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Variables: Index(['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine',\n",
      "       'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n",
      "       'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm',\n",
      "       'Temp9am', 'Temp3pm'],\n",
      "      dtype='object')\n",
      "Categorical Variables: Index(['RainTomorrow'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_model_num = df_model.columns[df_model.dtypes == 'float64']\n",
    "df_model_cat=df_model.columns[df_model.dtypes == 'object']\n",
    "print(\"Numeric Variables:\", df_model_num)\n",
    "print(\"Categorical Variables:\", df_model_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20202992",
   "metadata": {},
   "source": [
    "Check if all the numerical variables are accurately created and if we still have any non-numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "485f9a5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: (140787, 16)\n",
      "target shape: (140787,)\n"
     ]
    }
   ],
   "source": [
    "X=df_model[df_model_num]\n",
    "y = df_model.RainTomorrow\n",
    "print('features shape:', X.shape) \n",
    "print('target shape:', y.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ea30c6",
   "metadata": {},
   "source": [
    "Assigning the `RainTomorrow` as our response variable (y) and all other variables include one-hot-encoded values as X."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fadda0",
   "metadata": {},
   "source": [
    "# Commented code\n",
    "# -- DO WE NEED TO REMOVE?\n",
    "model_stats_columns=[\"Solver\", \"C\", \"Penalty\",\"Iteration\",\n",
    "                         \"AccuracyNone\",\"ConfusionMatrixNone\", \n",
    "                         \"MacroAvgPrecisionNone\",\"MacroAvgRecallNone\", \"MacroAvgF1ScoreNone\",\n",
    "                         \"WeightedAvgPrecisionNone\",\"WeightedAvgRecallNone\", \"WeightedAvgF1ScoreNone\",\n",
    "                         \"fprNone\", \"tprNone\",\n",
    "                         \"AccuracyBalanced\",\"ConfusionMatrixBalanced\", \n",
    "                         \"MacroAvgPrecisionBalanced\",\"MacroAvgRecallBalanced\", \"MacroAvgF1ScoreBalanced\",\n",
    "                         \"WeightedAvgPrecisionBalanced\",\"WeightedAvgRecallBalanced\", \"WeightedAvgF1ScoreBalanced\",\n",
    "                         \"fprBalanced\", \"tprBalanced\",\n",
    "                         \"Classes\"\n",
    "                        ]\n",
    "                        \n",
    "                        \n",
    " stats_dict[key] = [acc, conf, \n",
    "                  macro_avg_precision, macro_avg_recall,macro_avg_f1_score,\n",
    "                  weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                  fpr, tpr ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b607eb76",
   "metadata": {},
   "source": [
    "#### Data Distribution\n",
    "\n",
    "Check if the data distribution is balanced or not for the response variable `RainTomorrow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26445414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (8,5))\n",
    "df_model['RainTomorrow'].value_counts(normalize = True).plot(kind='bar', color= ['skyblue','navy'], alpha = 0.9, rot=0)\n",
    "plt.title('RainTomorrow Indicator No(0) and Yes(1) in the Imbalanced Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4e7da9",
   "metadata": {},
   "source": [
    "As expected, we see the data for `RainTomorrow` is imbalanced. Majority of the data is for `No` rain vs. `Yes' for `RainTomorrow`.\n",
    "\n",
    "We can observe that the presence of “0” and “1” is almost in the 78:22 ratio. We will be cognizant of the fact that our model may be not very effective if we don't solve for imbalance. We will discuss and adjust for this imbalance in our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30623463",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b1b442",
   "metadata": {},
   "source": [
    "# -- DO WE NEED TO REMOVE?\n",
    "model_stats_columns=[\"Model\",\"Solver\", \"C\", \"Penalty\",\"Iteration\",\n",
    "                         \"AccuracyNone\", \n",
    "                         \"MacroAvgPrecisionNone\",\n",
    "                         \"WeightedAvgPrecisionNone\",\n",
    "                         \"fprNone\", \"tprNone\",\n",
    "                         \"AccuracyBalanced\",\n",
    "                         \"MacroAvgPrecisionBalanced\",\n",
    "                         \"WeightedAvgPrecisionBalanced\",\n",
    "                         \"fprBalanced\", \"tprBalanced\",\n",
    "                         \"Classes\"\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f901e402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Model\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#model stats dataframe columns for class weight balanced and None\n",
    "model_stats_columns=[\"Model\",\"Solver\", \"C\", \"Penalty\",\"Iteration\",\n",
    "                         \"AccuracyNone\", \"MacroAvgPrecisionNone\",\"WeightedAvgPrecisionNone\",\"DiffMacro/WeightedNone\",\"fprNone\", \"tprNone\",\n",
    "                         \"AccuracyBalanced\",\"MacroAvgPrecisionBalanced\",\"WeightedAvgPrecisionBalanced\",\"DiffMacro/WeightedBalanced\",\"fprBalanced\", \"tprBalanced\", \n",
    "                         \"Classes\"\n",
    "                        ]\n",
    "\n",
    "\n",
    "def create_log_models(model_type,df, iterations,penalty, C, solver):\n",
    "    class_weight = ['balanced', None]\n",
    "    \n",
    "    #Create logreg object for both class weights\n",
    "    lr_clf_balanced = LogisticRegression(penalty=penalty, C=C, class_weight='balanced', solver=solver) \n",
    "    lr_clf_none = LogisticRegression(penalty=penalty, C=C, class_weight=None, solver=solver)\n",
    "    \n",
    "    #Store both objects in a dict for later retrival\n",
    "    lr_clf_dict = { \n",
    "                    \"balanced\": lr_clf_balanced,\n",
    "                    \"None\": lr_clf_none\n",
    "                    }\n",
    "\n",
    "    num_cv_iterations = iterations\n",
    "\n",
    "   \n",
    "    if \"RainTomorrow\" in df:\n",
    "        y = df[\"RainTomorrow\"].values # get the labels we want\n",
    "        del df[\"RainTomorrow\"] # get rid of the class label\n",
    "        X = df.values # use everything else to predict!\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    num_instances = len(y)\n",
    "    \n",
    "    cv_data = None\n",
    "    if model_type == \"shuffle\":\n",
    "        cv_data = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                             test_size  = 0.2, random_state = 123)\n",
    "\n",
    "    elif model_type == \"stratified\":\n",
    "        cv_data = StratifiedKFold(n_splits=iterations, random_state=123, shuffle=True)\n",
    "        cv_data.get_n_splits(X, y)\n",
    "       \n",
    "    #Initialize variables\n",
    "    iter_num=0\n",
    "    rows = []\n",
    "    stats_dict = {}\n",
    "    target_names = ['No', 'Yes']\n",
    "    classes = None    \n",
    "    scl_obj = StandardScaler()\n",
    "    \n",
    "    # Run for balanced first with same model and then None with same model\n",
    "    # store the results in same row of dataframe\n",
    "    # This helps to compare none and balanced macro avg\n",
    "   \n",
    "    for train_indices, test_indices in cv_data.split(X,y): \n",
    "        for cw in class_weight:\n",
    "            X_train = X[train_indices]\n",
    "            y_train = y[train_indices]\n",
    "        \n",
    "            scl_obj.fit(X_train)\n",
    "\n",
    "            X_test = X[test_indices]\n",
    "            y_test = y[test_indices]\n",
    "            \n",
    "            #Get the logistic regression object for the current cw class weight\n",
    "            key = None\n",
    "            if cw == None:\n",
    "                key = \"None\"\n",
    "            else:\n",
    "                key = cw\n",
    "                    \n",
    "            lr_clf = lr_clf_dict[key]\n",
    "            \n",
    "            try:\n",
    "                X_train_scaled = scl_obj.transform(X_train) \n",
    "                X_test_scaled = scl_obj.transform(X_test)\n",
    "\n",
    "                lr_clf.fit(X_train_scaled,y_train)  # train object\n",
    "                y_hat = lr_clf.predict(X_test_scaled) # get test set precitions\n",
    "                classes = lr_clf.classes_\n",
    "\n",
    "                acc = mt.accuracy_score(y_test,y_hat)\n",
    "                conf = mt.confusion_matrix(y_test,y_hat)\n",
    "                \n",
    "                class_report = classification_report(y_test, y_hat, target_names, output_dict=True)\n",
    "                \n",
    "                # Macro avg stats\n",
    "                macro_avg_precision = class_report[\"macro avg\"][\"precision\"]\n",
    "                macro_avg_recall = class_report[\"macro avg\"][\"recall\"]\n",
    "                macro_avg_f1_score = class_report[\"macro avg\"][\"f1-score\"]\n",
    "\n",
    "                #Weighted avg stats\n",
    "                weighted_avg_precision = class_report[\"weighted avg\"][\"precision\"]\n",
    "                weighted_avg_recall = class_report[\"weighted avg\"][\"recall\"]\n",
    "                weighted_avg_f1_score = class_report[\"weighted avg\"][\"f1-score\"]\n",
    "\n",
    "                # Create ROC Curve\n",
    "                y_test_01 = np.where(y_test ==\"Yes\", 1, [0])\n",
    "                y_hat_01 = np.where(y_hat ==\"Yes\", 1, [0])\n",
    "\n",
    "                fpr, tpr, threshold = metrics.roc_curve(y_test_01, y_hat_01)\n",
    "                #rows.append([model_type,solver,class_weight,C,penalty,iter_num, acc, conf, class_report, fpr,tpr,classes])\n",
    "                \n",
    "                #Create a dict of these stats for class weight\n",
    "                #dict will contain stats for balanced on one run, None for the next run\n",
    "                \n",
    "                                   \n",
    "                stats_dict[key] = [acc, \n",
    "                          macro_avg_precision, \n",
    "                          weighted_avg_precision,\n",
    "                          abs(weighted_avg_precision-macro_avg_precision),         \n",
    "                          fpr, tpr ]\n",
    "\n",
    "                print(model_type, solver,cw,C,penalty,iter_num,\"✅\")\n",
    "            except Exception as e:\n",
    "                print('Error:', str(e))\n",
    "                raise\n",
    "            #end try block  \n",
    "        #end first for loop\n",
    "        #When cursor comes here, model has ran for both None and balanced\n",
    "        #Create a single row of lists combining none and balanced \n",
    "        \n",
    "        row = [model_type, solver,C,penalty,iter_num] + stats_dict[\"None\"] + stats_dict['balanced'] + [classes]\n",
    "        rows.append(row)\n",
    "        iter_num+=1\n",
    "    #end next for loop\n",
    "    \n",
    "    #Create a dataframe with the model stats \n",
    "    df_ret = pd.DataFrame(rows, columns = model_stats_columns)\n",
    "    return df_ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f244c582",
   "metadata": {},
   "source": [
    "## Explain the Code Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eea1d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "penalty=['l1','l2', 'elasticnet', 'none']\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "model_type = ['shuffle', 'stratified']\n",
    "C=[1.0, 10.0, 100.0]\n",
    "iterations = 3\n",
    "\n",
    "#penalty=['l2']\n",
    "#solver = ['liblinear']\n",
    "#model_type = ['shuffle', 'stratified']\n",
    "#C=[1.0]\n",
    "\n",
    "model_perf_df = pd.DataFrame(columns= model_stats_columns)\n",
    "\n",
    "# Run all combinations of penalty, solver, model_type, C\n",
    "# Create a giant dataframe\n",
    "# Each row of dataframe contains stats for each combination of penalty, solver, model_type,C\n",
    "# same row contains the stats for both None and balanced class weight\n",
    "# so we can compare the balanced and None\n",
    "# and pick the model whose diff in precision (for macro avg) is lowest with highest accuracy\n",
    "# This model is the closest to real world\n",
    "\n",
    "for pen in penalty:\n",
    "    for c_index in C:\n",
    "        for solv in solver:\n",
    "            for mdl_type in model_type:\n",
    "                try:\n",
    "                    df_ret = create_log_models(model_type=mdl_type,df=df_model,iterations=iterations, penalty=pen, C=c_index, solver=solv)\n",
    "                    model_perf_df = model_perf_df.append(df_ret, ignore_index=True)\n",
    "                    \n",
    "                    #Model deletes RainTomorrow from dataframe\n",
    "                    #put it back from imputed data to run for another set of model\n",
    "                    df_model[\"RainTomorrow\"] = df_impute[\"RainTomorrow\"].values\n",
    "                except Exception as e:\n",
    "                    print(\"Error in running\", str(e))\n",
    "                    continue\n",
    "                            \n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d037a40",
   "metadata": {},
   "source": [
    "## Explain the Code Above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1acbda",
   "metadata": {},
   "source": [
    "In these models we used two different methodologies for cross validation namely `Shuffle` and `Stratified`.\n",
    "\n",
    "`ShuffleSplit` - ShuffleSplit is similar to Cross Validation where we can specify the percentage of split for Train and Test data. However, in regular cross-validation, the data is not split randomly, so, it is good to shuffle the targets before applying the ‘cross-validation’.\n",
    "\n",
    "\n",
    "`Stratified` CV technique is very useful with unbalanced dataset. As discussed above our dataset is not balanced and rightly so, we don't expect it to rain and no-rain days to be equal in Australia. The data is expected to be unbalanced and expected to be such in future as well. So using stratified sampling techniques gives us the ability to preserve the proportion of the Rain days vs non-rain days in our dataset. We can be confident that the Train and Test split data is not leaving out important information like entire dataset is of `No` rain days which will give highly inaccurate output eventhough the accuracy might be maintained. \n",
    "\n",
    "In stratified sampling, the data is k-1 split in favor of Train vs Test data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "References: \n",
    "https://towardsdatascience.com/understanding-8-types-of-cross-validation-80c935a4976d\n",
    "https://mclguide.readthedocs.io/en/latest/sklearn/cv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00bcf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total models and each model with balanced and None class weight\n",
    "\n",
    "model_count = len(model_perf_df)\n",
    "\n",
    "model_perf_df[[\"Model\",\"AccuracyNone\",\"DiffMacro/WeightedNone\",\"AccuracyBalanced\", \"DiffMacro/WeightedBalanced\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0785a1",
   "metadata": {},
   "source": [
    "After running the big `Logistic Regression` model for several combinations. We got output for 198 models.\n",
    "\n",
    "To compare the outputs and make it easier to identify the most appropriate model in terms of accuracy, precision and other factors applicable for Machine Learning models. We decided to put a list of subset of variables including:\n",
    "\n",
    "`Model` -> This specifies which technique was used for the logistic model. In this case its between ShuffleSplit and Stratified.\n",
    "\n",
    "`AccuracyNone` -> This variable to specify the Accuracy observed by the model where data was not BALANCED.\n",
    "\n",
    "`DiffMacro/WeightedNone` -> This variable takes the Macro Average and Weighted Average of Precision from the classification matrix and calculates the difference. The reason to calculate the difference is to check how much variation is in the Precision values based on how the data is split. More details about Precision and Averages is provided below. This variation is calculated on the non BALANCED data.\n",
    "\n",
    "`AccuracyBalanced` -> This variable to specify the Accuracy observed by the model where data was BALANCED.\n",
    "\n",
    "`DiffMacro/WeightedBalanced` -> Same as above this variable calculates the difference between Macro and Weighted Average of Precision of a BALANCED data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d18ba7",
   "metadata": {},
   "source": [
    "#### Important Terms\n",
    "\n",
    "`Accuracy` -> Accuracy is a ratio of correctly predicted observation to the total observations. It is a very important aspect to define the success of a model but just the measurement on its own can be deceiving if the observations are not equal for each class. In such cases we might be predicting accurately for one particular class with large observation and may not do very well for other classes.\n",
    "\n",
    "`Precision` -> Precision is the ratio of correctly predicted positive observations to the total predicted positive observations. Precision = TP/TP+FP  \n",
    "\n",
    "`Weighted Average` -> The weighted average can be calculated on various output variables of the classification report like Precision, Recall, f1-score. As the name suggests it gives the weighted average of the parameter based on the number of observations or values for each class.\n",
    "\n",
    "`Macro Average` -> Similar to weighted average, macro average can also be calculated on various output variables of the classification report like Precision, Recall, f1-score. However, the similarity ends here as unlike weighted average, we don't use weights based on the number of observations, rather equal weights are given to each class to calcualte the value. This tells us if the Precision is as good if the dataset was balanced.\n",
    "\n",
    "References:\n",
    "https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/\n",
    "https://datascience.stackexchange.com/questions/65839/macro-average-and-weighted-average-meaning-in-classification-report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e02993cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  matplotlib import pyplot\n",
    "import seaborn\n",
    "\n",
    "def draw_scatter(df, x,y):\n",
    "\n",
    "    seaborn.set(style='ticks')\n",
    "    solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "    fg = seaborn.FacetGrid(data=model_perf_df, hue='Solver', hue_order=solver, height=8, aspect=1.61)\n",
    "    fg.map(pyplot.scatter, 'Models', 'AccuracyNone' ).add_legend()\n",
    "\n",
    "    for i, ax in enumerate(fg.fig.axes):   \n",
    "         ax.set_xticklabels(ax.get_xticklabels(), rotation = 90)\n",
    "\n",
    "\n",
    "#Reference: https://stackoverflow.com/questions/14885895/color-by-column-values-in-matplotlib\n",
    "#Ref for Axis rotation: https://stackoverflow.com/questions/26540035/rotate-label-text-in-seaborn-factorplot/43256409#43256409"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a9cb22",
   "metadata": {},
   "source": [
    "## Look only Stratified models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fcf485",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create a plot by looking shuffle vs stratefied\n",
    "\n",
    "model_perf_df['Models'] = model_perf_df['Model'] + \" / Penalty:\" + model_perf_df['Penalty'] + \" / C:\"+model_perf_df['C'].astype(str)\n",
    "\n",
    "model_perf_df = model_perf_df.sort_values(by=['Models'],ascending=False)\n",
    "\n",
    "#Sort by accuracy and take top 5\n",
    "\n",
    "model_perf_df = model_perf_df.nlargest(5, 'AccuracyNone')\n",
    "\n",
    "draw_scatter(df=model_perf_df, x='Models', y='AccuracyNone')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b748013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets focus on Stratified\n",
    "\n",
    "#Remove all shuffle\n",
    "\n",
    "model_perf_df.drop(model_perf_df[model_perf_df.Model == \"shuffle\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29359d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a plot by looking shuffle vs stratefied\n",
    "\n",
    "model_perf_df['Models'] = model_perf_df['Model'] + \" / Penalty:\" + model_perf_df['Penalty'] + \" / C:\"+model_perf_df['C'].astype(str)\n",
    "model_perf_df = model_perf_df.sort_values(by=['Models'],ascending=False)\n",
    "draw_scatter(df=model_perf_df, x='Models', y='AccuracyNone')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179bd00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = model_perf_df['Models'].unique()\n",
    "model_perf_df['Models'] = pd.Categorical(model_perf_df['Models'], order)\n",
    "model_perf_df.sort_values(by=['Models'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b30adb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fg = seaborn.FacetGrid(data=model_perf_df, hue='Solver', hue_order=solver, height=10, aspect=1.61)\n",
    "fg.map(pyplot.scatter, 'Models', 'DiffMacro/WeightedBalanced').add_legend()\n",
    "\n",
    "for i, ax in enumerate(fg.fig.axes):   ## getting all axes of the fig object\n",
    "     ax.set_xticklabels(ax.get_xticklabels(), rotation = 90)\n",
    "\n",
    "#Reference: https://stackoverflow.com/questions/14885895/color-by-column-values-in-matplotlib\n",
    "\n",
    "#Ref for Axis rotation: https://stackoverflow.com/questions/26540035/rotate-label-text-in-seaborn-factorplot/43256409#43256409"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0e4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC Curve of top\n",
    "\n",
    "top_model = model_perf_df.head(1)\n",
    "\n",
    "for index, row in top_model.iterrows():\n",
    "    fpr = row[\"fprNone\"]\n",
    "    tpr = row[\"tprNone\"]\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d08191",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f91e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc =metrics.auc([0.,0.0591311, 1.],[0.,0.64278846,1.])\n",
    "fpr = [0.,0.0591311, 1.]\n",
    "tpr = [0.,0.64278846,1.]\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fa1969",
   "metadata": {},
   "source": [
    "# Stop here for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331fb01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_svm_model(df, class_weight, iterations):\n",
    "    num_cv_iterations = iterations\n",
    "  \n",
    "    if \"RainTomorrow\" in df:\n",
    "        y = df[\"RainTomorrow\"].values # get the labels we want\n",
    "        del df[\"RainTomorrow\"] # get rid of the class label\n",
    "        X = df.values # use everything else to predict!\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    num_instances = len(y)\n",
    "    cv_data = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                             test_size  = 0.2, random_state = 123)\n",
    "\n",
    "    iter_num=0\n",
    "    rows = []\n",
    "    scl_obj = StandardScaler()\n",
    "    for train_indices, test_indices in cv_data.split(X,y): \n",
    "        X_train = X[train_indices]\n",
    "        y_train = y[train_indices]\n",
    "        \n",
    "        scl_obj.fit(X_train)\n",
    "\n",
    "        X_test = X[test_indices]\n",
    "        y_test = y[test_indices]\n",
    "        try:\n",
    "            X_train_scaled = scl_obj.transform(X_train) \n",
    "            X_test_scaled = scl_obj.transform(X_test)\n",
    "            y_hat = None\n",
    "          \n",
    "            svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
    "            svm_clf.fit(X_train_scaled, y_train)  # train object\n",
    "            y_hat = svm_clf.predict(X_test_scaled) # get test set precitions\n",
    "            classes = svm_clf.classes_\n",
    "\n",
    "            acc = mt.accuracy_score(y_test,y_hat)\n",
    "            conf = mt.confusion_matrix(y_test,y_hat)\n",
    "            target_names = ['No', 'Yes']\n",
    "            class_report = classification_report(y_test, y_hat, target_names, output_dict=True)\n",
    "            \n",
    "            # Macro avg stats\n",
    "            macro_avg_precision = class_report[\"macro avg\"][\"precision\"]\n",
    "            macro_avg_recall = class_report[\"macro avg\"][\"recall\"]\n",
    "            macro_avg_f1_score = class_report[\"macro avg\"][\"f1-score\"]\n",
    "            \n",
    "            #Weighted avg stats\n",
    "            weighted_avg_precision = class_report[\"weighted avg\"][\"precision\"]\n",
    "            weighted_avg_recall = class_report[\"weighted avg\"][\"recall\"]\n",
    "            weighted_avg_f1_score = class_report[\"weighted avg\"][\"f1-score\"]\n",
    "            \n",
    "            \n",
    "            # Create ROC Curve\n",
    "            y_test_01 = np.where(y_test ==\"Yes\", 1, [0])\n",
    "            y_hat_01 = np.where(y_hat ==\"Yes\", 1, [0])\n",
    "\n",
    "            fpr, tpr, threshold = metrics.roc_curve(y_test_01, y_hat_01)\n",
    "            rows.append([\"svm\",None,class_weight,0,None,iter_num, acc, conf, class_report, fpr,tpr, classes])\n",
    "\n",
    "            model_stats[cw] = [acc, conf, target_names, ]\n",
    "            \n",
    "            \n",
    "            print(\"Iteration\",iter_num,\"-----> Done\")\n",
    "        except Exception as e:\n",
    "            print('Error:', str(e))\n",
    "            raise\n",
    "        iter_num+=1   \n",
    "   \n",
    "    df_ret = pd.DataFrame(rows, columns=[\"ModelType\",\"Solver\", \"ClassWeight\", \"C\", \"Penalty\",\"Iteration\",\"Accuracy\",\"ConfusionMatrix\", \n",
    "                                         \"ClassificationReport\",\"fpr\", \"tpr\", \"classes\"])\n",
    "    return df_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbe50c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b8cac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_perf_df.sort_values(by=['Accuracy'],ascending=False).head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b666e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1aaa84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3d4eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ret_svm = create_svm_model(df=df_model, class_weight='balanced',iterations=3)\n",
    "model_perf_df = model_perf_df.append(dt_ret_svm)\n",
    "for index, row in df_ret_svm.iterrows():\n",
    "    fpr = row[\"fpr\"]\n",
    "    tpr = row[\"tpr\"]\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac8c511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's make a pandas Series with the names and values, and plot them\n",
    "\n",
    "weights = pd.Series(lr_clf.coef_[0],index=df_model.columns)\n",
    "weights.plot(kind='bar', figsize=(14,6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abcb3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = mt.ConfusionMatrixDisplay(confusion_matrix=conf[1])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a900e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a2eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11923732",
   "metadata": {},
   "source": [
    "## Alternative/Shorter version of logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b10b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this does the exact same thing as the above block of code, but with shorter syntax\n",
    "\n",
    "for iter_num,(train_indices, test_indices) in enumerate(cv_object.split(X,y)):\n",
    "    lr_clf.fit([train_indices],y[train_indices])  # train object\n",
    "    y_hat = lr_clf.predict([test_indices]) # get test set precitions\n",
    "\n",
    "    # print the accuracy and confusion matrix \n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", mt.accuracy_score(y[test_indices],y_hat)) \n",
    "    print(\"confusion matrix\\n\",mt.confusion_matrix(y[test_indices],y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f51d416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Function\n",
    "#Run with various parameters\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def logistic_regression_short(df, iterations,class_weight, penalty, solver, C, l1_ratio):\n",
    "    lr_clf = LogisticRegression(penalty=penalty, C=C, class_weight=class_weight, solver=solver) \n",
    "\n",
    "  \n",
    "    if \"RainTomorrow\" in df:\n",
    "        y = df[\"RainTomorrow\"].values # get the labels we want\n",
    "        del df[\"RainTomorrow\"] # get rid of the class label\n",
    "        X = df.values # use everything else to predict!\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    rows = []\n",
    "    iter_num = 0\n",
    "    \n",
    "    try:\n",
    "        # train the reusable logisitc regression model on the training data\n",
    "        accuracies = cross_val_score(lr_clf, X, y=y, cv=iterations) \n",
    "        for index, acc in enumerate(accuracies):\n",
    "            rows.append([solver,class_weight,C,penalty,index, acc, None])\n",
    "    except Exception as e:\n",
    "        print(\"Error in running\", solver,class_weight,C,penalty,iter_num, str(e))\n",
    "        \n",
    "        \n",
    "    df_ret = pd.DataFrame(rows, columns=[\"Solver\", \"ClassWeight\", \"C\", \"Penalty\",\"Iteration\",\"Accuracy\",\"ConfusionMatrix\"])\n",
    "    return df_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67001765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and here is an even shorter way of getting the accuracies for each training and test set\n",
    "\n",
    "accuracies = logistic_regression_short() # this also can help with parallelism\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add7c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at feature importance \n",
    "\n",
    "import shap # SHAP for Explaining Models\n",
    "shap.initjs()\n",
    "# Create a tree explainer and understanding the values we have \n",
    "shap_ex = shap.LinearExplainer(lr_clf, X_test)\n",
    "vals = shap_ex.shap_values(X_test)\n",
    "shap.summary_plot(vals, df_model.columns, plot_type=\"bar\")\n",
    "\n",
    "# Reference: https://shap.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae66d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the effect of all the features through SHAP summary plot:\n",
    "explainer = shap.Explainer(lr_clf, X_train, feature_names=df_model.columns)\n",
    "shap_values = explainer(X_test)\n",
    "shap.plots.beeswarm(shap_values)\n",
    "\n",
    "# Reference: https://shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/linear_models/Sentiment%20Analysis%20with%20Logistic%20Regression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702a175f",
   "metadata": {},
   "source": [
    "Explaining the logistic model for Rain Tomorrow prediction:\n",
    "\n",
    "SHAP summary plots give us a birds-eye view of feature importance and what is driving it. The values of the features are their TF-IDF values.\n",
    "\n",
    "The above SHAP summary plot is made of many dots. Each dot has three characteristics:\n",
    "\n",
    "Vertical location shows what feature it is depicting\n",
    "Color shows whether that feature was high or low for that row of the dataset.\n",
    "Horizontal location shows whether the effect of that value caused a higher or lower prediction.\n",
    "For example, the point in the upper left was for 'Sunshine' that caused lower chances of Rain Tomorrow, reducing the prediction by 2.\n",
    "\n",
    "Some things the summary plot is  able to easily pick out:-\n",
    "\n",
    "Remember that higher means more likely to be negative, so in the plots above the “red” features are actually helping raise the chance for Rain Tomorrow, while the negative features are lowering the chance for Rain Tomorrow.\n",
    "The model ignored around 56 features which were of lower importance in predicting the chances of Rain Tomorrow.\n",
    "Usually 'WindGustSpeed' has moderate effert on the prediction, but there are extreme cases of 'WindGustSpeed' where a high value still caused moderate level of prediction.\n",
    "High values of Goal scored caused higher predictions, and low values caused low predictions\n",
    "\n",
    "Reference: https://www.kaggle.com/dansbecker/advanced-uses-of-shap-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf8422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explaining why a sample weather record # 200 is classified as Rain Tomorrow (Yes/No)?\n",
    "ind = 200\n",
    "shap.plots.force(shap_values[ind])\n",
    "# Reference: https://shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/linear_models/Sentiment%20Analysis%20with%20Logistic%20Regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0fef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap plot provides another global view of the model’s behavior, with a focus on predictions for Rain Tomorrow.\n",
    "#shap.plots.heatmap(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b66aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_by_time = {\n",
    "    '3pm': [f for f in df_impute if '3pm' in f],\n",
    "    '9am': [f for f in df_impute if '9am' in f],\n",
    "    'not_time_based': [f for f in df_impute if '9am' not in f and '3pm' not in f]\n",
    "}\n",
    "\n",
    "groups_by_type = {\n",
    "    'humidity_and_rain': ['Rainfall',\n",
    "                          'Evaporation',\n",
    "                          'Humidity9am',\n",
    "                          'Humidity3pm',\n",
    "                          'RainToday'],\n",
    "    'temperature': ['MinTemp',\n",
    "                    'MaxTemp',\n",
    "                    'Temp9am',\n",
    "                    'Temp3pm'],\n",
    "    'sun_and_clouds': ['Cloud9am',\n",
    "                       'Cloud3pm',\n",
    "                       'Sunshine'],\n",
    "    'wind_and_pressure': ['WindGustDir',\n",
    "                          'WindGustSpeed',\n",
    "                          'WindDir9am',\n",
    "                          'WindDir3pm',\n",
    "                          'WindSpeed9am',\n",
    "                          'WindSpeed3pm',\n",
    "                          'Pressure9am',\n",
    "                          'Pressure3pm'],\n",
    "    'location': ['Location']\n",
    "}\n",
    "\n",
    "shap_time = grouped_shap(shap_vals, df_impute, groups_by_time)\n",
    "shap_type = grouped_shap(shap_vals, df_impute, groups_by_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4eff68",
   "metadata": {},
   "source": [
    "### Oversampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062f7ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "no = df_impute[df_impute.RainTomorrow == 0]\n",
    "yes = df_impute[df_impute.RainTomorrow == 1]\n",
    "yes_oversampled = resample(yes, replace=True, n_samples=len(no), random_state=123)\n",
    "oversampled = pd.concat([no, yes_oversampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b3084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_dummies using oversampled dataframe\n",
    "\n",
    "# perform one-hot encoding of the categorical data \"embarked\"\n",
    "gust_df = pd.get_dummies(oversampled.WindGustDir,prefix='GustDir')\n",
    "wind3pm_df = pd.get_dummies(oversampled.WindDir3pm,prefix='Wind3pm')\n",
    "wind9am_df = pd.get_dummies(oversampled.WindDir9am,prefix='Wind9am')\n",
    "oversampled = pd.concat((oversampled,gust_df, wind3pm_df, wind9am_df),axis=1) # add back into the dataframe\n",
    "\n",
    "# replace the current Sex atribute with something slightly more intuitive and readable\n",
    "oversampled['IsRainToday'] = oversampled.RainToday=='Yes' \n",
    "oversampled.IsRainToday = oversampled.IsRainToday.astype(np.int)\n",
    "\n",
    "oversampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f690ebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,5))\n",
    "oversampled.RainTomorrow.value_counts(normalize = True).plot(kind='bar', color= ['skyblue','navy'], alpha = 0.9, rot=0)\n",
    "plt.title('RainTomorrow Indicator No(0) and Yes(1) after Oversampling (Balanced Dataset)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611cb7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6df2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping categorical columns\n",
    "\n",
    "oversampled = oversampled.drop(['WindDir3pm', 'WindDir9am', 'WindGustDir', 'RainToday'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba911d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shufflesplit using oversampled dataframe\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if \"RainTomorrow\" in oversampled:\n",
    "    y = oversampled[\"RainTomorrow\"].values # get the labels we want\n",
    "    del oversampled[\"RainTomorrow\"] # get rid of the class label\n",
    "    X_over = oversampled.values # use everything else to predict!\n",
    "\n",
    "    ## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    #    have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "#    of the object and set it up. This object will be able to split our data into \n",
    "#    training and testing splits\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object_over = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2, random_state = 123)\n",
    "                         \n",
    "print(cv_object_over)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
