{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1746415f",
   "metadata": {},
   "source": [
    "# Lab One : Visualization and Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a4b9ff",
   "metadata": {},
   "source": [
    "### Group 3 - Members:\n",
    "\n",
    "_Apurv Mittal_<br>\n",
    "_Seemant Srivastava_<br>\n",
    "_Ravi Sivaraman_<br>\n",
    "_Tai Chowdhury_<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a96353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from shapely.geometry import Point\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.utils import resample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce8247b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore Warnings on final\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "888e9335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Australia weather data\n",
    "df = pd.read_csv(\"weatherAUS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a61b1c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/1/08</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/2/08</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/3/08</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/4/08</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/5/08</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  12/1/08   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  12/2/08   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  12/3/08   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  12/4/08   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  12/5/08   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
       "0           W           44.0          W  ...        71.0         22.0   \n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2         WSW           46.0          W  ...        38.0         30.0   \n",
       "3          NE           24.0         SE  ...        45.0         16.0   \n",
       "4           W           41.0        ENE  ...        82.0         33.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
       "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
       "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
       "3       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
       "4       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  View the top rows of the data imported\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bba99724",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Date and Location\n",
    "\n",
    "df = df.drop(['Date', 'Location'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91546666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Variables: Index(['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine',\n",
      "       'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n",
      "       'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm',\n",
      "       'Temp9am', 'Temp3pm'],\n",
      "      dtype='object')\n",
      "Categorical Variables: Index(['WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Removing records which are blank for Rain today and Rain tomorrow\n",
    "\n",
    "df.dropna(subset = [\"RainToday\"], inplace=True)\n",
    "df.dropna(subset = [\"RainTomorrow\"], inplace=True)\n",
    "\n",
    "\n",
    "# Seperate the data into categorical and numeric\n",
    "\n",
    "df_num = df.columns[df.dtypes == 'float64']\n",
    "df_cat=df.columns[df.dtypes == 'object']\n",
    "print(\"Numeric Variables:\", df_num)\n",
    "print(\"Categorical Variables:\", df_cat)\n",
    "\n",
    "# REFERENCE: https://www.kite.com/python/answers/how-to-drop-empty-rows-from-a-pandas-dataframe-in-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5529fc00",
   "metadata": {},
   "source": [
    "#### Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ac571fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute data (numeric) based on the mean for RainToday and RainTomorrow\n",
    "\n",
    "df_impute = df\n",
    "mat_yesno = df[df_num].groupby([df['RainToday'],df['RainTomorrow']]).mean()\n",
    "RAINTODAY=0\n",
    "RAINTOMORROW=1\n",
    "COUNTER = 0\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        for indexattr in mat_yesno.iloc[COUNTER].index:\n",
    "            df_impute.loc[(df_impute[\"RainToday\"] == mat_yesno.iloc[COUNTER].name[RAINTODAY] ) \n",
    "                          & (df_impute[\"RainTomorrow\"] == mat_yesno.iloc[COUNTER].name[RAINTOMORROW]) \n",
    "                          & (df_impute[indexattr].isnull()), indexattr] = mat_yesno.iloc[COUNTER][indexattr]\n",
    "        COUNTER = COUNTER + 1\n",
    "\n",
    "        \n",
    "        \n",
    "# Impute data (categorical) with mode of each variable\n",
    "\n",
    "df_impute['WindDir9am'] = df_impute['WindDir9am'].fillna(df_impute['WindDir9am'].mode()[0])\n",
    "df_impute['WindGustDir'] = df_impute['WindGustDir'].fillna(df_impute['WindGustDir'].mode()[0])\n",
    "df_impute['WindDir3pm'] = df_impute['WindDir3pm'].fillna(df_impute['WindDir3pm'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecca19ef",
   "metadata": {},
   "source": [
    "As mentioned above, we imputed data for all numeric variables with the means for the combination of `RainToday` and `RainTomorrow`. We calcualted the value for `RainToday` and `RainTomorrow` both as \"No\" and imputed the data for the missing variables for such combination, similary calculated `RainToday` as \"Yes\" and `RainTomorrow` as \"No\" and imputed the mean value for the variable so and so forth.\n",
    "\n",
    "For categorical variables `WindDir9am`, `WindDir3pm` are covering the direction of the wind at different 9 am and 3 pm respectively, while `WindGustDir`is the direction of the wind gust. All these variables are about the direction and and the largest missing variable is `6.8%` for Wind Direction at 9 am. We decided to impute this data with the Mode for each of the categorical variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb585c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Variables: Index(['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine',\n",
      "       'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n",
      "       'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm',\n",
      "       'Temp9am', 'Temp3pm'],\n",
      "      dtype='object')\n",
      "Categorical Variables: Index(['WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_impute_num = df.columns[df.dtypes == 'float64']\n",
    "df_impute_cat=df.columns[df.dtypes == 'object']\n",
    "print(\"Numeric Variables:\", df_num)\n",
    "print(\"Categorical Variables:\", df_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe083dc",
   "metadata": {},
   "source": [
    "## Creating different dataframes for continous and categorical variables.\n",
    "Assigning the `RainTomorrow` as our response variable (y) and all other continous variable as X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af99221",
   "metadata": {},
   "source": [
    "### Handling Class Imbalance For Rainfall Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d0f3fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep the original data\n",
    "df_model = df_impute.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be50b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change RainToday from categorical to continuous\n",
    "\n",
    "df_model[\"IsRainToday\"] = df_impute['RainToday']\n",
    "#df_model['IsRainTomorrow'] = df_impute['RainTomorrow']\n",
    "\n",
    "df_model['IsRainToday'].replace({'No': 0, 'Yes': 1},inplace = True)\n",
    "#df_model['IsRainTomorrow'].replace({'No': 0, 'Yes': 1},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43dd811a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_impute (140787, 21)\n",
      "df_model (140787, 22)\n"
     ]
    }
   ],
   "source": [
    "print(\"df_impute\", df_impute.shape)\n",
    "print(\"df_model\", df_model.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cee4734a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "      <th>IsRainToday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.032209</td>\n",
       "      <td>8.890686</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WNW</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.684394</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.032209</td>\n",
       "      <td>8.890686</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>WSW</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>3.635105</td>\n",
       "      <td>3.684394</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.032209</td>\n",
       "      <td>8.890686</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WSW</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>3.635105</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.032209</td>\n",
       "      <td>8.890686</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>E</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>3.635105</td>\n",
       "      <td>3.684394</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.032209</td>\n",
       "      <td>8.890686</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>NW</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145454</th>\n",
       "      <td>3.5</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.032209</td>\n",
       "      <td>8.890686</td>\n",
       "      <td>E</td>\n",
       "      <td>31.0</td>\n",
       "      <td>ESE</td>\n",
       "      <td>E</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1024.7</td>\n",
       "      <td>1021.2</td>\n",
       "      <td>3.635105</td>\n",
       "      <td>3.684394</td>\n",
       "      <td>9.4</td>\n",
       "      <td>20.9</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145455</th>\n",
       "      <td>2.8</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.032209</td>\n",
       "      <td>8.890686</td>\n",
       "      <td>E</td>\n",
       "      <td>31.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>ENE</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1024.6</td>\n",
       "      <td>1020.3</td>\n",
       "      <td>3.635105</td>\n",
       "      <td>3.684394</td>\n",
       "      <td>10.1</td>\n",
       "      <td>22.4</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145456</th>\n",
       "      <td>3.6</td>\n",
       "      <td>25.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.032209</td>\n",
       "      <td>8.890686</td>\n",
       "      <td>NNW</td>\n",
       "      <td>22.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>N</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1023.5</td>\n",
       "      <td>1019.1</td>\n",
       "      <td>3.635105</td>\n",
       "      <td>3.684394</td>\n",
       "      <td>10.9</td>\n",
       "      <td>24.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145457</th>\n",
       "      <td>5.4</td>\n",
       "      <td>26.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.032209</td>\n",
       "      <td>8.890686</td>\n",
       "      <td>N</td>\n",
       "      <td>37.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>WNW</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1016.8</td>\n",
       "      <td>3.635105</td>\n",
       "      <td>3.684394</td>\n",
       "      <td>12.5</td>\n",
       "      <td>26.1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145458</th>\n",
       "      <td>7.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.032209</td>\n",
       "      <td>8.890686</td>\n",
       "      <td>SE</td>\n",
       "      <td>28.0</td>\n",
       "      <td>SSE</td>\n",
       "      <td>N</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1019.4</td>\n",
       "      <td>1016.5</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140787 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine WindGustDir  \\\n",
       "0          13.4     22.9       0.6     6.032209  8.890686           W   \n",
       "1           7.4     25.1       0.0     6.032209  8.890686         WNW   \n",
       "2          12.9     25.7       0.0     6.032209  8.890686         WSW   \n",
       "3           9.2     28.0       0.0     6.032209  8.890686          NE   \n",
       "4          17.5     32.3       1.0     6.032209  8.890686           W   \n",
       "...         ...      ...       ...          ...       ...         ...   \n",
       "145454      3.5     21.8       0.0     6.032209  8.890686           E   \n",
       "145455      2.8     23.4       0.0     6.032209  8.890686           E   \n",
       "145456      3.6     25.3       0.0     6.032209  8.890686         NNW   \n",
       "145457      5.4     26.9       0.0     6.032209  8.890686           N   \n",
       "145458      7.8     27.0       0.0     6.032209  8.890686          SE   \n",
       "\n",
       "        WindGustSpeed WindDir9am WindDir3pm  WindSpeed9am  ...  Humidity3pm  \\\n",
       "0                44.0          W        WNW          20.0  ...         22.0   \n",
       "1                44.0        NNW        WSW           4.0  ...         25.0   \n",
       "2                46.0          W        WSW          19.0  ...         30.0   \n",
       "3                24.0         SE          E          11.0  ...         16.0   \n",
       "4                41.0        ENE         NW           7.0  ...         33.0   \n",
       "...               ...        ...        ...           ...  ...          ...   \n",
       "145454           31.0        ESE          E          15.0  ...         27.0   \n",
       "145455           31.0         SE        ENE          13.0  ...         24.0   \n",
       "145456           22.0         SE          N          13.0  ...         21.0   \n",
       "145457           37.0         SE        WNW           9.0  ...         24.0   \n",
       "145458           28.0        SSE          N          13.0  ...         24.0   \n",
       "\n",
       "        Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  \\\n",
       "0            1007.7       1007.1  8.000000  3.684394     16.9     21.8   \n",
       "1            1010.6       1007.8  3.635105  3.684394     17.2     24.3   \n",
       "2            1007.6       1008.7  3.635105  2.000000     21.0     23.2   \n",
       "3            1017.6       1012.8  3.635105  3.684394     18.1     26.5   \n",
       "4            1010.8       1006.0  7.000000  8.000000     17.8     29.7   \n",
       "...             ...          ...       ...       ...      ...      ...   \n",
       "145454       1024.7       1021.2  3.635105  3.684394      9.4     20.9   \n",
       "145455       1024.6       1020.3  3.635105  3.684394     10.1     22.4   \n",
       "145456       1023.5       1019.1  3.635105  3.684394     10.9     24.5   \n",
       "145457       1021.0       1016.8  3.635105  3.684394     12.5     26.1   \n",
       "145458       1019.4       1016.5  3.000000  2.000000     15.1     26.0   \n",
       "\n",
       "        RainToday  RainTomorrow IsRainToday  \n",
       "0              No            No           0  \n",
       "1              No            No           0  \n",
       "2              No            No           0  \n",
       "3              No            No           0  \n",
       "4              No            No           0  \n",
       "...           ...           ...         ...  \n",
       "145454         No            No           0  \n",
       "145455         No            No           0  \n",
       "145456         No            No           0  \n",
       "145457         No            No           0  \n",
       "145458         No            No           0  \n",
       "\n",
       "[140787 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26445414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (8,5))\n",
    "df_model['RainTomorrow'].value_counts(normalize = True).plot(kind='bar', color= ['skyblue','navy'], alpha = 0.9, rot=0)\n",
    "plt.title('RainTomorrow Indicator No(0) and Yes(1) in the Imbalanced Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6abca3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (8,5))\n",
    "df_model['RainToday'].value_counts(normalize = True).plot(kind='bar', color= ['skyblue','navy'], alpha = 0.9, rot=0)\n",
    "plt.title('RainToday Indicator No(0) and Yes(1) in the Imbalanced Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a25167",
   "metadata": {},
   "source": [
    "We can observe that the presence of “0” and “1” is almost in the 78:22 ratio. So there is a class imbalance and we have to deal with it. To fight against the class imbalance, we will use here the oversampling of the minority class. Since the size of the dataset is quite small, majority class subsampling wouldn’t make much sense here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae0a9ae",
   "metadata": {},
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad32c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one-hot encoding of the categorical data\n",
    "\n",
    "gust_df = pd.get_dummies(df_model.WindGustDir,prefix='GustDir')\n",
    "wind3pm_df = pd.get_dummies(df_model.WindDir3pm,prefix='Wind3pm')\n",
    "wind9am_df = pd.get_dummies(df_model.WindDir9am,prefix='Wind9am')\n",
    "df_model = pd.concat((df_model,gust_df, wind3pm_df, wind9am_df),axis=1) # add back into the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "404f163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop categorical columns\n",
    "\n",
    "df_model = df_model.drop(['WindDir3pm', 'WindDir9am', 'WindGustDir', 'RainToday'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d39ba70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there 1's and 0's in the RainToday column? True\n"
     ]
    }
   ],
   "source": [
    "#Check if Yes is replaced as 1\n",
    "\n",
    "print(\"Are there 1's and 0's in the RainToday column?\", \n",
    "      (df_model['IsRainToday'].sum() > 0) and (df_model['IsRainToday'].sum() < len(df_model['IsRainToday'])))\n",
    "\n",
    "#Non zero output means there is a mixture of 1's and 0's\n",
    "#if sum is less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "485f9a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: (140787, 16)\n",
      "target shape: (140787,)\n"
     ]
    }
   ],
   "source": [
    "X=df_model[df_num]\n",
    "y = df_model.RainTomorrow\n",
    "print('features shape:', X.shape) \n",
    "print('target shape:', y.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30623463",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0809377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Function\n",
    "#Run with various parameters\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def create_models(model_type,df, iterations,class_weight, penalty, solver, C, l1_ratio):\n",
    "    lr_clf = LogisticRegression(penalty=penalty, C=C, class_weight=class_weight, solver=solver) \n",
    "\n",
    "    num_cv_iterations = iterations\n",
    "    rain_tom_df = None\n",
    "   \n",
    "    if \"RainTomorrow\" in df:\n",
    "        y = df[\"RainTomorrow\"].values # get the labels we want\n",
    "        del df[\"RainTomorrow\"] # get rid of the class label\n",
    "        X = df.values # use everything else to predict!\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    num_instances = len(y)\n",
    "    if model_type == \"shuffle\":\n",
    "        cv_data = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                             test_size  = 0.2, random_state = 123)\n",
    "\n",
    "    elif model_type == \"stratified\":\n",
    "        cv_data = StratifiedKFold(n_splits=iterations, random_state=123, shuffle=True)\n",
    "        cv_data.get_n_splits(X, y)\n",
    "\n",
    "       \n",
    "    iter_num=0\n",
    "    rows = []\n",
    "    scl_obj = StandardScaler()\n",
    "    for train_indices, test_indices in cv_data.split(X,y): \n",
    "        X_train = X[train_indices]\n",
    "        y_train = y[train_indices]\n",
    "        \n",
    "        scl_obj.fit(X_train)\n",
    "\n",
    "        X_test = X[test_indices]\n",
    "        y_test = y[test_indices]\n",
    "        try:\n",
    "            X_train_scaled = scl_obj.transform(X_train) \n",
    "            X_test_scaled = scl_obj.transform(X_test)\n",
    "            y_hat = None\n",
    "            if model_type == \"svm\":\n",
    "                svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
    "                svm_clf.fit(X_train_scaled, y_train)  # train object\n",
    "                y_hat = svm_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "            else:\n",
    "                # shuffle and stratifed models using logistic reg\n",
    "                lr_clf.fit(X_train_scaled,y_train)  # train object\n",
    "                y_hat = lr_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "            acc = mt.accuracy_score(y_test,y_hat)\n",
    "            conf = mt.confusion_matrix(y_test,y_hat)\n",
    "            target_names = ['No', 'Yes']\n",
    "            class_report = classification_report(y_test, y_hat, target_names)\n",
    "            \n",
    "            # Create ROC Curve\n",
    "            y_test_01 = np.where(y_test ==\"Yes\", 1, [0])\n",
    "            print(\"y_test\", y_test)\n",
    "            print(\"y_test_01\", y_test_01)\n",
    "            print(\"y_hat\", y_hat)\n",
    "            y_hat_01 = np.where(y_hat ==\"Yes\", 1, [0])\n",
    "\n",
    "            fpr, tpr, threshold = metrics.roc_curve(y_test_01, y_hat_01)\n",
    "            print(\"fpr\", fpr)\n",
    "            print(\"tr\", tpr)\n",
    "            rows.append([model_type,solver,class_weight,C,penalty,iter_num, acc, conf, class_report, fpr,tpr])\n",
    "\n",
    "            print(\"Iteration\",solver,class_weight,C,penalty,iter_num,\"-----> Done\")\n",
    "            disp = mt.ConfusionMatrixDisplay(confusion_matrix=conf, display_labels=lr_clf.classes_)\n",
    "            disp.plot()\n",
    "        except Exception as e:\n",
    "            print('Error:', str(e))\n",
    "            raise\n",
    "        iter_num+=1   \n",
    "   \n",
    "    df_ret = pd.DataFrame(rows, columns=[\"ModelType\",\"Solver\", \"ClassWeight\", \"C\", \"Penalty\",\"Iteration\",\"Accuracy\",\"ConfusionMatrix\", \n",
    "                                         \"ClassificationReport\",\"fpr\", \"tpr\"])\n",
    "    return df_ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252ad476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "Error in running Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "Error in running 'NoneType' object has no attribute 'iterrows'\n",
      "Error: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "Error in running Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "Error in running 'NoneType' object has no attribute 'iterrows'\n"
     ]
    }
   ],
   "source": [
    "penalty=['l1','l2', 'elasticnet', 'none']\n",
    "class_weight = ['balanced', None]\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "model_type = ['shuffle', 'stratified']\n",
    "\n",
    "#penalty=['l2']\n",
    "#class_weight = [None]\n",
    "#solver = ['liblinear']\n",
    "#model_type = ['shuffle', \"stratified\"]\n",
    "\n",
    "\n",
    "lg_types = []\n",
    "C=1.0\n",
    "\n",
    "for pen in penalty:\n",
    "    for cw in class_weight:\n",
    "        for solv in solver:\n",
    "            for split in model_type:\n",
    "                lg_types.append([solv,cw,C,pen])\n",
    "                try:\n",
    "                    df_ret = create_models(model_type=split,df=df_model,iterations=3,class_weight=cw, penalty=pen, C=C, solver=solv, l1_ratio=None)\n",
    "                    df_model[\"RainTomorrow\"] = df_impute[\"RainTomorrow\"].values\n",
    "                    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "                    for index, row in df_ret.iterrows():\n",
    "                        fpr = row[\"fpr\"]\n",
    "                        tpr = row[\"tpr\"]\n",
    "                        print(\"fpr\", fpr)\n",
    "                        print(\"tpr\", tpr)\n",
    "                        roc_auc = metrics.auc(fpr, tpr)\n",
    "                        plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "                        plt.legend(loc = 'lower right')\n",
    "                        plt.plot([0, 1], [0, 1],'r--')\n",
    "                        plt.xlim([0, 1])\n",
    "                        plt.ylim([0, 1])\n",
    "                        plt.ylabel('True Positive Rate')\n",
    "                        plt.xlabel('False Positive Rate')\n",
    "                        plt.show()\n",
    "                except Exception as e:\n",
    "                    print(\"Error in running\", str(e))\n",
    "                    continue\n",
    "                            \n",
    "\n",
    "df_ret_svm = create_models(model_type=\"svm\", df=df_model, iterations=0,class_weight=None, penalty=None, C=0, solver=None, l1_ratio=None)\n",
    "for index, row in df_ret_svm.iterrows():\n",
    "    fpr = row[\"fpr\"]\n",
    "    tpr = row[\"tpr\"]\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "lg_types_df = pd.DataFrame(lg_types, columns=[\"Solver\", \"ClassWeight\", \"C\", \"Penalty\"])\n",
    "#print(lg_types_df)          \n",
    " \n",
    "\n",
    "#df_ret = [logistic_regression(df=df_impute,iterations=3,class_weight=row[0], penalty=row[1], C=row[2], solver=row[3], l1_ratio=None) for row in zip(lg_types_df['ClassWeight'],lg_types_df[\"Penalty\"],lg_types_df['C'], lg_types_df[\"Solver\"])]\n",
    "#df_ret = logistic_regression(df=df_impute, iterations=3, class_weight='balanced',penalty='l2' ,C=1.0, solver='liblinear', l1_ratio=None)\n",
    "#print(df_ret)\n",
    "\n",
    "\n",
    "#Source for panda iterations https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31c037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ret[\"fpr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8438c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = mt.ConfusionMatrixDisplay(confusion_matrix=conf[1])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0ec2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657602ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11923732",
   "metadata": {},
   "source": [
    "## Alternative/Shorter version of logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b10b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this does the exact same thing as the above block of code, but with shorter syntax\n",
    "\n",
    "for iter_num,(train_indices, test_indices) in enumerate(cv_object.split(X,y)):\n",
    "    lr_clf.fit([train_indices],y[train_indices])  # train object\n",
    "    y_hat = lr_clf.predict([test_indices]) # get test set precitions\n",
    "\n",
    "    # print the accuracy and confusion matrix \n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", mt.accuracy_score(y[test_indices],y_hat)) \n",
    "    print(\"confusion matrix\\n\",mt.confusion_matrix(y[test_indices],y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c0f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Function\n",
    "#Run with various parameters\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def logistic_regression_short(df, iterations,class_weight, penalty, solver, C, l1_ratio):\n",
    "    lr_clf = LogisticRegression(penalty=penalty, C=C, class_weight=class_weight, solver=solver) \n",
    "\n",
    "  \n",
    "    if \"RainTomorrow\" in df:\n",
    "        y = df[\"RainTomorrow\"].values # get the labels we want\n",
    "        del df[\"RainTomorrow\"] # get rid of the class label\n",
    "        X = df.values # use everything else to predict!\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    rows = []\n",
    "    iter_num = 0\n",
    "    \n",
    "    try:\n",
    "        # train the reusable logisitc regression model on the training data\n",
    "        accuracies = cross_val_score(lr_clf, X, y=y, cv=iterations) \n",
    "        for index, acc in enumerate(accuracies):\n",
    "            rows.append([solver,class_weight,C,penalty,index, acc, None])\n",
    "    except Exception as e:\n",
    "        print(\"Error in running\", solver,class_weight,C,penalty,iter_num, str(e))\n",
    "        \n",
    "        \n",
    "    df_ret = pd.DataFrame(rows, columns=[\"Solver\", \"ClassWeight\", \"C\", \"Penalty\",\"Iteration\",\"Accuracy\",\"ConfusionMatrix\"])\n",
    "    return df_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67001765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and here is an even shorter way of getting the accuracies for each training and test set\n",
    "\n",
    "accuracies = logistic_regression_short() # this also can help with parallelism\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc28f12e",
   "metadata": {},
   "source": [
    "## Stratified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05795cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified CV \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def stratified_k_fold(iterations):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=10, random_state=123, shuffle=True)\n",
    "    skf.get_n_splits(X, y)\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9251a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we can change some of the parameters interactively\n",
    "from ipywidgets import widgets as wd\n",
    "\n",
    "def lr_explor(cost):\n",
    "    lr_clf = LogisticRegression(penalty='l2', C=cost, class_weight=None,solver='liblinear') # get object\n",
    "    accuracies = cross_val_score(lr_clf,X_new,y=y,cv=cv_object) # this also can help with parallelism\n",
    "    print(accuracies)\n",
    "\n",
    "wd.interact(lr_explor,cost=(0.001,5.0,0.05),__manual=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e5acea",
   "metadata": {},
   "source": [
    "### Interpreting the weights - Need to add explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348b8984",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# interpret the weights\n",
    "\n",
    "# iterate over the coefficients\n",
    "weights = lr_clf.coef_.T # take transpose to make a column vector\n",
    "variable_names = oversampled.columns\n",
    "for coef, name in zip(weights,variable_names):\n",
    "    print(name, 'has weight of', coef[0])\n",
    "    \n",
    "# does this look correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f910e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#StandardScaler for df_impute\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# we want to normalize the features based upon the mean and standard deviation of each column. \n",
    "# However, we do not want to accidentally use the testing data to find out the mean and std (this would be snooping)\n",
    "# to Make things easier, let's start by just using whatever was last stored in the variables:\n",
    "##    X_train , y_train , X_test, y_test (they were set in a for loop above)\n",
    "\n",
    "# scale attributes by the training set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train) # find scalings for each column that make this zero mean and unit std\n",
    "# the line of code above only looks at training data to get mean and std and we can use it \n",
    "# to transform new feature data\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) # apply those means and std to the test set (without snooping at the test set values)\n",
    "\n",
    "# train the model just as before\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.05, solver='liblinear') # get object, the 'C' value is less (can you guess why??)\n",
    "lr_clf.fit(X_train_scaled,y_train)  # train object\n",
    "\n",
    "y_hat = lr_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf )\n",
    "\n",
    "# sort these attributes and spit them out\n",
    "zip_vars = zip(lr_clf.coef_.T,df_impute.columns) # combine attributes\n",
    "zip_vars = sorted(zip_vars)\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0]) # now print them outv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#StandardScaler for oversampled\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# we want to normalize the features based upon the mean and standard deviation of each column. \n",
    "# However, we do not want to accidentally use the testing data to find out the mean and std (this would be snooping)\n",
    "# to Make things easier, let's start by just using whatever was last stored in the variables:\n",
    "##    X_train , y_train , X_test, y_test (they were set in a for loop above)\n",
    "\n",
    "# scale attributes by the training set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train) # find scalings for each column that make this zero mean and unit std\n",
    "# the line of code above only looks at training data to get mean and std and we can use it \n",
    "# to transform new feature data\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) # apply those means and std to the test set (without snooping at the test set values)\n",
    "\n",
    "# train the model just as before\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.05, solver='liblinear') # get object, the 'C' value is less (can you guess why??)\n",
    "lr_clf.fit(X_train_scaled,y_train)  # train object\n",
    "\n",
    "y_hat = lr_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf )\n",
    "\n",
    "# sort these attributes and spit them out\n",
    "zip_vars = zip(lr_clf.coef_.T,oversampled.columns) # combine attributes\n",
    "zip_vars = sorted(zip_vars)\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0]) # now print them outv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4a5605",
   "metadata": {},
   "source": [
    "### Needs attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418afa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's make a pandas Series with the names and values, and plot them\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "weights = pd.Series(lr_clf.coef_[0],index=oversampled.columns)\n",
    "weights.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efcbd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# we want to normalize the features based upon the mean and standard deviation of each column. \n",
    "# However, we do not want to accidentally use the testing data to find out the mean and std (this would be snooping)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "# you can apply the StandardScaler function inside of the cross-validation loop \n",
    "#  but this requires the use of PipeLines in scikit. \n",
    "#  A pipeline can apply feature pre-processing and data fitting in one compact notation\n",
    "#  Here is an example!\n",
    "\n",
    "std_scl = StandardScaler()\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.05, solver='liblinear') \n",
    "\n",
    "# create the pipline\n",
    "piped_object = Pipeline([('scale', std_scl),  # do this\n",
    "                         ('logit_model', lr_clf)]) # and then do this\n",
    "\n",
    "weights = []\n",
    "# run the pipline cross validated\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object.split(X,y)):\n",
    "    piped_object.fit(X_new[train_indices],y[train_indices])  # train object\n",
    "    # it is a little odd getting trained objects from a  pipeline:\n",
    "    weights.append(piped_object.named_steps['logit_model'].coef_[0])\n",
    "    \n",
    "\n",
    "weights = np.array(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d64616c",
   "metadata": {},
   "source": [
    "## Needs Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b17d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "plotly.offline.init_notebook_mode() # run at the start of every notebook\n",
    "\n",
    "error_y=dict(\n",
    "            type='data',\n",
    "            array=np.std(weights,axis=0),\n",
    "            visible=True\n",
    "        )\n",
    "\n",
    "graph1 = {'x': oversampled.columns,\n",
    "          'y': np.mean(weights,axis=0),\n",
    "    'error_y':error_y,\n",
    "       'type': 'bar'}\n",
    "\n",
    "fig = dict()\n",
    "fig['data'] = [graph1]\n",
    "fig['layout'] = {'title': 'Logistic Regression Weights, with error bars'}\n",
    "\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e45886",
   "metadata": {},
   "source": [
    "### Needs Attention***  need to decide on the attributes for Xnew. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b727b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xnew = oversampled[['Year','WindGustSpeed','RainToday']].values\n",
    "\n",
    "weights = []\n",
    "# run the pipline corssvalidated\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object.split(Xnew,y)):\n",
    "    piped_object.fit(Xnew[train_indices],y[train_indices])  # train object\n",
    "    weights.append(piped_object.named_steps['logit_model'].coef_[0])\n",
    "    \n",
    "weights = np.array(weights)\n",
    "\n",
    "error_y=dict(\n",
    "            type='data',\n",
    "            array=np.std(weights,axis=0),\n",
    "            visible=True\n",
    "        )\n",
    "\n",
    "graph1 = {'x': ['Year','WindGustSpeed','RainToday'],\n",
    "          'y': np.mean(weights,axis=0),\n",
    "    'error_y':error_y,\n",
    "       'type': 'bar'}\n",
    "\n",
    "fig = dict()\n",
    "fig['data'] = [graph1]\n",
    "fig['layout'] = {'title': 'Logistic Regression Weights, with error bars'}\n",
    "\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e703154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime import lime_tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc40e2f",
   "metadata": {},
   "source": [
    "## SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49223b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca22bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM Using df_impute\n",
    "\n",
    "# okay, so run through the cross validation loop and set the training and testing variable for one single iteration\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9a3730",
   "metadata": {},
   "outputs": [],
   "source": [
    "##SVM Using df_impute dataframe\n",
    "\n",
    "# lets investigate SVMs on the data and play with the parameters and kernels\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# train the model just as before\n",
    "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(X_train_scaled, y_train)  # train object\n",
    "\n",
    "y_hat = svm_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f5e197",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM Using oversampled dataframe\n",
    "\n",
    "# okay, so run through the cross validation loop and set the training and testing variable for one single iteration\n",
    "for train_indices, test_indices in cv_object.split_over(X,y): \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58409e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##SVM Using df_impute\n",
    "\n",
    "# lets investigate SVMs on the data and play with the parameters and kernels\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# train the model just as before\n",
    "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(X_train_scaled, y_train)  # train object\n",
    "\n",
    "y_hat = svm_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e789d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the support vectors\n",
    "print(svm_clf.support_vectors_.shape)\n",
    "print(svm_clf.support_.shape)\n",
    "print(svm_clf.n_support_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c682c53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svm_clf.coef_)\n",
    "weights = pd.Series(svm_clf.coef_[0],index=df_imputed.columns)\n",
    "weights.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3c0108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do some different analysis with the SVM and look at the instances that were chosen as support vectors\n",
    "\n",
    "# now lets look at the support for the vectors and see if we they are indicative of anything\n",
    "# grabe the rows that were selected as support vectors (these are usually instances that are hard to classify)\n",
    "\n",
    "# make a dataframe of the training data\n",
    "df_tested_on = oversampled.iloc[train_indices].copy() # saved from above, the indices chosen for training\n",
    "# now get the support vectors from the trained model\n",
    "df_support = oversampled.iloc[svm_clf.support_,:].copy()\n",
    "\n",
    "df_support['RainTomorrow'] = y[svm_clf.support_] # add back in the 'Survived' Column to the pandas dataframe\n",
    "oversampled['RainTomorrow'] = y # also add it back in for the original data\n",
    "df_support.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b8ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets see the statistics of these attributes\n",
    "from pandas.plotting import boxplot\n",
    "\n",
    "# group the original data and the support vectors\n",
    "df_grouped_support = df_support.groupby(['RainTomorrow'])\n",
    "df_grouped = oversampled.groupby(['RainTomorrow'])\n",
    "\n",
    "# plot KDE of Different variables\n",
    "vars_to_plot = ['Date','WindGustDir','RainToday','RainfallAmount']\n",
    "\n",
    "for v in vars_to_plot:\n",
    "    plt.figure(figsize=(10,4))\n",
    "    # plot support vector stats\n",
    "    plt.subplot(1,2,1)\n",
    "    ax = df_grouped_support[v].plot.kde() \n",
    "    plt.legend(['No','Yes'])\n",
    "    plt.title(v+' (Instances chosen as Support Vectors)')\n",
    "    \n",
    "    # plot original distributions\n",
    "    plt.subplot(1,2,2)\n",
    "    ax = df_grouped[v].plot.kde() \n",
    "    plt.legend(['No','Yes'])\n",
    "    plt.title(v+' (Original)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f50aac",
   "metadata": {},
   "source": [
    "   ### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab55e4e",
   "metadata": {},
   "source": [
    "*Principal Component Analysis* is a method to reduce the number of features from a large features, while still maintaining the overall accuracy of the model. In a large dataset with hundreds of features, there are only a select few may have impact compared to the rest. The dimensions that influcence the models rise rapids and elbows at a point, then asymptotes. After that point, there is diminishing returns while adding more features. \n",
    "\n",
    "Having more features will ultimately help, but considering the amount of reduction in dimensions and the processing power to compute the models and complexities are drastically reduced. Improvement in accuracy of the model doesn't justify the extra processing power or the compleixities in the model.\n",
    "\n",
    "In the above PCA analysis, there are 16 continuous features. However PCA indicates the graph flattens at 11 features, and adding five more dimensions doesnt improve the model as much.\n",
    "\n",
    "At 8 components the model explains the variance is 92.9%, and at 12 components variance explained is 99.44%.\n",
    "\n",
    "Anything more than 8 components isn't going to add much better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba52db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Code\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# standardizing the features\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components = 16)\n",
    "\n",
    "principalComponents = pca.fit_transform(X)\n",
    "\n",
    "principalDF = pd.DataFrame(data = principalComponents)\n",
    "\n",
    "#finalDF = pd.concat([principalDF, df[['RainTomorrow']]], axis =1)\n",
    "\n",
    "plt.subplots(figsize=(6, 6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance');\n",
    "print('Cumulative Explained variance of components: ',sum(pca.explained_variance_ratio_[0:199]) )\n",
    "print(pca)\n",
    "\n",
    "\n",
    "variation = pd.DataFrame(pca.explained_variance_ratio_)\n",
    "cumulative_variation = pd.DataFrame(pca.explained_variance_ratio_.cumsum())\n",
    "print(\"Variance explained by each component: \",variation)\n",
    "print (\"\\n Cumulative Variance explained by additional component: \", cumulative_variation)\n",
    "\n",
    "# Reference : https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35968c71",
   "metadata": {},
   "source": [
    "### Oversampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57153a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "no = df_impute[df_impute.RainTomorrow == 0]\n",
    "yes = df_impute[df_impute.RainTomorrow == 1]\n",
    "yes_oversampled = resample(yes, replace=True, n_samples=len(no), random_state=123)\n",
    "oversampled = pd.concat([no, yes_oversampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b3084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_dummies using oversampled dataframe\n",
    "\n",
    "# perform one-hot encoding of the categorical data \"embarked\"\n",
    "gust_df = pd.get_dummies(oversampled.WindGustDir,prefix='GustDir')\n",
    "wind3pm_df = pd.get_dummies(oversampled.WindDir3pm,prefix='Wind3pm')\n",
    "wind9am_df = pd.get_dummies(oversampled.WindDir9am,prefix='Wind9am')\n",
    "oversampled = pd.concat((oversampled,gust_df, wind3pm_df, wind9am_df),axis=1) # add back into the dataframe\n",
    "\n",
    "# replace the current Sex atribute with something slightly more intuitive and readable\n",
    "oversampled['IsRainToday'] = oversampled.RainToday=='Yes' \n",
    "oversampled.IsRainToday = oversampled.IsRainToday.astype(np.int)\n",
    "\n",
    "oversampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f690ebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,5))\n",
    "oversampled.RainTomorrow.value_counts(normalize = True).plot(kind='bar', color= ['skyblue','navy'], alpha = 0.9, rot=0)\n",
    "plt.title('RainTomorrow Indicator No(0) and Yes(1) after Oversampling (Balanced Dataset)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ff5a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd65684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping categorical columns\n",
    "\n",
    "oversampled = oversampled.drop(['WindDir3pm', 'WindDir9am', 'WindGustDir', 'RainToday'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d468e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shufflesplit using oversampled dataframe\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if \"RainTomorrow\" in oversampled:\n",
    "    y = oversampled[\"RainTomorrow\"].values # get the labels we want\n",
    "    del oversampled[\"RainTomorrow\"] # get rid of the class label\n",
    "    X_over = oversampled.values # use everything else to predict!\n",
    "\n",
    "    ## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    #    have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "#    of the object and set it up. This object will be able to split our data into \n",
    "#    training and testing splits\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object_over = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2, random_state = 123)\n",
    "                         \n",
    "print(cv_object_over)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
