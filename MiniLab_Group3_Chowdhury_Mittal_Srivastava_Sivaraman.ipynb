{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1746415f",
   "metadata": {},
   "source": [
    "# Lab One : Visualization and Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a4b9ff",
   "metadata": {},
   "source": [
    "### Group 3 - Members:\n",
    "\n",
    "_Apurv Mittal_<br>\n",
    "_Seemant Srivastava_<br>\n",
    "_Ravi Sivaraman_<br>\n",
    "_Tai Chowdhury_<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a96353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from shapely.geometry import Point\n",
    "#import geopandas as gpd\n",
    "#from geopandas import GeoDataFrame\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8247b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore Warnings on final\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888e9335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Australia weather data\n",
    "df = pd.read_csv(\"weatherAUS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61b1c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  View the top rows of the data imported\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ff1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Date and Location\n",
    "\n",
    "df = df.drop(['Date', 'Location'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91546666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing records which are blank for Rain today and Rain tomorrow\n",
    "\n",
    "df.dropna(subset = [\"RainToday\"], inplace=True)\n",
    "df.dropna(subset = [\"RainTomorrow\"], inplace=True)\n",
    "\n",
    "\n",
    "# Seperate the data into categorical and numeric\n",
    "\n",
    "df_num = df.columns[df.dtypes == 'float64']\n",
    "df_cat=df.columns[df.dtypes == 'object']\n",
    "print(\"Numeric Variables:\", df_num)\n",
    "print(\"Categorical Variables:\", df_cat)\n",
    "\n",
    "\n",
    "\n",
    "# REFERENCE: https://www.kite.com/python/answers/how-to-drop-empty-rows-from-a-pandas-dataframe-in-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5529fc00",
   "metadata": {},
   "source": [
    "#### Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac571fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute data (numeric) based on the mean for RainToday and RainTomorrow\n",
    "\n",
    "df_impute = df\n",
    "mat_yesno = df[df_num].groupby([df['RainToday'],df['RainTomorrow']]).mean()\n",
    "RAINTODAY=0\n",
    "RAINTOMORROW=1\n",
    "COUNTER = 0\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        for indexattr in mat_yesno.iloc[COUNTER].index:\n",
    "            df_impute.loc[(df_impute[\"RainToday\"] == mat_yesno.iloc[COUNTER].name[RAINTODAY] ) \n",
    "                          & (df_impute[\"RainTomorrow\"] == mat_yesno.iloc[COUNTER].name[RAINTOMORROW]) \n",
    "                          & (df_impute[indexattr].isnull()), indexattr] = mat_yesno.iloc[COUNTER][indexattr]\n",
    "        COUNTER = COUNTER + 1\n",
    "\n",
    "        \n",
    "        \n",
    "# Impute data (categorical) with mode of each variable\n",
    "\n",
    "df_impute['WindDir9am'] = df_impute['WindDir9am'].fillna(df_impute['WindDir9am'].mode()[0])\n",
    "df_impute['WindGustDir'] = df_impute['WindGustDir'].fillna(df_impute['WindGustDir'].mode()[0])\n",
    "df_impute['WindDir3pm'] = df_impute['WindDir3pm'].fillna(df_impute['WindDir3pm'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecca19ef",
   "metadata": {},
   "source": [
    "As mentioned above, we imputed data for all numeric variables with the means for the combination of `RainToday` and `RainTomorrow`. We calcualted the value for `RainToday` and `RainTomorrow` both as \"No\" and imputed the data for the missing variables for such combination, similary calculated `RainToday` as \"Yes\" and `RainTomorrow` as \"No\" and imputed the mean value for the variable so and so forth.\n",
    "\n",
    "For categorical variables `WindDir9am`, `WindDir3pm` are covering the direction of the wind at different 9 am and 3 pm respectively, while `WindGustDir`is the direction of the wind gust. All these variables are about the direction and and the largest missing variable is `6.8%` for Wind Direction at 9 am. We decided to impute this data with the Mode for each of the categorical variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aa55ea",
   "metadata": {},
   "source": [
    "## 8.New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5fe94e",
   "metadata": {},
   "source": [
    "   ### New Feature 1: Added State a new feature\n",
    "   \n",
    "   The original dataset we downloaded had just `Cities`, but we want to include `State`, as some analysis are done for the entire state. We found the dataset for Australian cities and state and then created a dataframe from Cities/State csv file and then joined with the original dataset to create a new feature called `State`.\n",
    "   \n",
    " \n",
    " The code to add the cities state are done in `Simple Statistics` section, we are referencing here the code on how it is done.\n",
    " \n",
    "#Add State\n",
    "state_df = pd.read_csv(\"loc.csv\")\n",
    "df_impute = pd.merge(df_impute, state_df, on='Location', how='outer')\n",
    "df_impute.isnull().sum()\n",
    "\n",
    "`State` is an useful parameter for our EDA analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af98204",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_impute[\"Rainfall\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a86248",
   "metadata": {},
   "source": [
    "## 9. Exceptional Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb585c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_impute_num = df.columns[df.dtypes == 'float64']\n",
    "df_impute_cat=df.columns[df.dtypes == 'object']\n",
    "print(\"Numeric Variables:\", df_num)\n",
    "print(\"Categorical Variables:\", df_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe083dc",
   "metadata": {},
   "source": [
    "Creating different dataframes for continous and categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485f9a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_impute[df_num]\n",
    "y = df.RainTomorrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7f002e",
   "metadata": {},
   "source": [
    "Assigning the `RainTomorrow` as our response variable (y) and all other continous variable as X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6897f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('features shape:', X.shape) \n",
    "print('target shape:', y.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037a3b0c",
   "metadata": {},
   "source": [
    "   ### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51ed4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Code\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# standardizing the features\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components = 16)\n",
    "\n",
    "principalComponents = pca.fit_transform(X)\n",
    "\n",
    "principalDF = pd.DataFrame(data = principalComponents)\n",
    "\n",
    "#finalDF = pd.concat([principalDF, df[['RainTomorrow']]], axis =1)\n",
    "\n",
    "plt.subplots(figsize=(6, 6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance');\n",
    "print('Cumulative Explained variance of components: ',sum(pca.explained_variance_ratio_[0:199]) )\n",
    "print(pca)\n",
    "\n",
    "\n",
    "variation = pd.DataFrame(pca.explained_variance_ratio_)\n",
    "cumulative_variation = pd.DataFrame(pca.explained_variance_ratio_.cumsum())\n",
    "print(\"Variance explained by each component: \",variation)\n",
    "print (\"\\n Cumulative Variance explained by additional component: \", cumulative_variation)\n",
    "\n",
    "# Reference : https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e353c840",
   "metadata": {},
   "source": [
    "*Principal Component Analysis* is a method to reduce the number of features from a large features, while still maintaining the overall accuracy of the model. In a large dataset with hundreds of features, there are only a select few may have impact compared to the rest. The dimensions that influcence the models rise rapids and elbows at a point, then asymptotes. After that point, there is diminishing returns while adding more features. \n",
    "\n",
    "Having more features will ultimately help, but considering the amount of reduction in dimensions and the processing power to compute the models and complexities are drastically reduced. Improvement in accuracy of the model doesn't justify the extra processing power or the compleixities in the model.\n",
    "\n",
    "In the above PCA analysis, there are 16 continuous features. However PCA indicates the graph flattens at 11 features, and adding five more dimensions doesnt improve the model as much.\n",
    "\n",
    "At 8 components the model explains the variance is 92.9%, and at 12 components variance explained is 99.44%.\n",
    "\n",
    "Anything more than 8 components isn't going to add much better accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af99221",
   "metadata": {},
   "source": [
    "### Handling Class Imbalance For Rainfall Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c9cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_impute['RainToday'].replace({'No': 0, 'Yes': 1},inplace = True)\n",
    "df_impute['RainTomorrow'].replace({'No': 0, 'Yes': 1},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26445414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (8,5))\n",
    "df_impute['RainTomorrow'].value_counts(normalize = True).plot(kind='bar', color= ['skyblue','navy'], alpha = 0.9, rot=0)\n",
    "plt.title('RainTomorrow Indicator No(0) and Yes(1) in the Imbalanced Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a25167",
   "metadata": {},
   "source": [
    "We can observe that the presence of “0” and “1” is almost in the 78:22 ratio. So there is a class imbalance and we have to deal with it. To fight against the class imbalance, we will use here the oversampling of the minority class. Since the size of the dataset is quite small, majority class subsampling wouldn’t make much sense here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83127df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "no = df_impute[df_impute.RainTomorrow == 0]\n",
    "yes = df_impute[df_impute.RainTomorrow == 1]\n",
    "yes_oversampled = resample(yes, replace=True, n_samples=len(no), random_state=123)\n",
    "oversampled = pd.concat([no, yes_oversampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f690ebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,5))\n",
    "oversampled.RainTomorrow.value_counts(normalize = True).plot(kind='bar', color= ['skyblue','navy'], alpha = 0.9, rot=0)\n",
    "plt.title('RainTomorrow Indicator No(0) and Yes(1) after Oversampling (Balanced Dataset)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f9b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(oversampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8306082",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd91933",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# perform one-hot encoding of the categorical data \"embarked\"\n",
    "gust_df = pd.get_dummies(df_impute.WindGustDir,prefix='GustDir')\n",
    "wind3pm_df = pd.get_dummies(df_impute.WindDir3pm,prefix='Wind3pm')\n",
    "wind9am_df = pd.get_dummies(df_impute.WindDir9am,prefix='Wind9am')\n",
    "df_impute = pd.concat((df_impute,gust_df, wind3pm_df, wind9am_df),axis=1) # add back into the dataframe\n",
    "\n",
    "# replace the current Sex atribute with something slightly more intuitive and readable\n",
    "df_impute['IsRainToday'] = df_impute.RainToday=='Yes' \n",
    "df_impute.IsRainToday = df_impute.IsRainToday.astype(np.int)\n",
    "\n",
    "df_impute.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64d897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping categorical columns\n",
    "\n",
    "df_impute = df_impute.drop(['WindDir3pm', 'WindDir9am', 'WindGustDir', 'RainToday'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde88e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_dummies using oversampled dataframe\n",
    "\n",
    "# perform one-hot encoding of the categorical data \"embarked\"\n",
    "gust_df = pd.get_dummies(oversampled.WindGustDir,prefix='GustDir')\n",
    "wind3pm_df = pd.get_dummies(oversampled.WindDir3pm,prefix='Wind3pm')\n",
    "wind9am_df = pd.get_dummies(oversampled.WindDir9am,prefix='Wind9am')\n",
    "oversampled = pd.concat((oversampled,gust_df, wind3pm_df, wind9am_df),axis=1) # add back into the dataframe\n",
    "\n",
    "# replace the current Sex atribute with something slightly more intuitive and readable\n",
    "oversampled['IsRainToday'] = oversampled.RainToday=='Yes' \n",
    "oversampled.IsRainToday = oversampled.IsRainToday.astype(np.int)\n",
    "\n",
    "oversampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480c746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping categorical columns\n",
    "\n",
    "oversampled = oversampled.drop(['WindDir3pm', 'WindDir9am', 'WindGustDir', 'RainToday'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a713d482",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317f0e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if \"RainTomorrow\" in df_impute:\n",
    "    y = df_impute[\"RainTomorrow\"].values # get the labels we want\n",
    "    del df_impute[\"RainTomorrow\"] # get rid of the class label\n",
    "    X = df_impute.values # use everything else to predict!\n",
    "\n",
    "    ## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    #    have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "#    of the object and set it up. This object will be able to split our data into \n",
    "#    training and testing splits\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2, random_state = 123)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87274406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shufflesplit using oversampled dataframe\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if \"RainTomorrow\" in oversampled:\n",
    "    y = oversampled[\"RainTomorrow\"].values # get the labels we want\n",
    "    del oversampled[\"RainTomorrow\"] # get rid of the class label\n",
    "    X = oversampled.values # use everything else to predict!\n",
    "\n",
    "    ## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    #    have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "#    of the object and set it up. This object will be able to split our data into \n",
    "#    training and testing splits\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object_over = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2, random_state = 123)\n",
    "                         \n",
    "print(cv_object_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30623463",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ff806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Using df_impute\n",
    "\n",
    "# run logistic regression and vary some parameters\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "lr_clf = LogisticRegression(penalty='elasticnet', C=1.0, class_weight='balanced', solver='saga', l1_ratio=1) # get object\n",
    "\n",
    "# now we can use the cv_object that we setup before to iterate through the \n",
    "#    different training and testing sets. Each time we will reuse the logisitic regression \n",
    "#    object, but it gets trained on different data each time we use it.\n",
    "\n",
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "lr_clf.fit(X_train,y_train)  # train object\n",
    "y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print(\"====Iteration\",iter_num,\" ====\")\n",
    "print(\"accuracy\", acc )\n",
    "print(\"confusion matrix\\n\",conf)\n",
    "iter_num+=1    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7c1615",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Using oversampled dataframe\n",
    "\n",
    "# run logistic regression and vary some parameters\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "lr_clf = LogisticRegression(penalty='elasticnet', C=1.0, class_weight=None, solver='saga', l1_ratio=1) # get object\n",
    "\n",
    "# now we can use the cv_object that we setup before to iterate through the \n",
    "#    different training and testing sets. Each time we will reuse the logisitic regression \n",
    "#    object, but it gets trained on different data each time we use it.\n",
    "\n",
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in cv_object_over.split(X,y): \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "lr_clf.fit(X_train,y_train)  # train object\n",
    "y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print(\"====Iteration\",iter_num,\" ====\")\n",
    "print(\"accuracy\", acc )\n",
    "print(\"confusion matrix\\n\",conf)\n",
    "iter_num+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b10b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this does the exact same thing as the above block of code, but with shorter syntax\n",
    "\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object.split(X,y)):\n",
    "    lr_clf.fit(X_new[train_indices],y[train_indices])  # train object\n",
    "    y_hat = lr_clf.predict(X_new[test_indices]) # get test set precitions\n",
    "\n",
    "    # print the accuracy and confusion matrix \n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", mt.accuracy_score(y[test_indices],y_hat)) \n",
    "    print(\"confusion matrix\\n\",mt.confusion_matrix(y[test_indices],y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67001765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and here is an even shorter way of getting the accuracies for each training and test set\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(lr_clf, X_new, y=y, cv=cv_object) # this also can help with parallelism\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9251a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we can change some of the parameters interactively\n",
    "from ipywidgets import widgets as wd\n",
    "\n",
    "def lr_explor(cost):\n",
    "    lr_clf = LogisticRegression(penalty='l2', C=cost, class_weight=None,solver='liblinear') # get object\n",
    "    accuracies = cross_val_score(lr_clf,X_new,y=y,cv=cv_object) # this also can help with parallelism\n",
    "    print(accuracies)\n",
    "\n",
    "wd.interact(lr_explor,cost=(0.001,5.0,0.05),__manual=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e5acea",
   "metadata": {},
   "source": [
    "### Interpreting the weights - Need to add explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348b8984",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# interpret the weights\n",
    "\n",
    "# iterate over the coefficients\n",
    "weights = lr_clf.coef_.T # take transpose to make a column vector\n",
    "variable_names = oversampled.columns\n",
    "for coef, name in zip(weights,variable_names):\n",
    "    print(name, 'has weight of', coef[0])\n",
    "    \n",
    "# does this look correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f910e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# we want to normalize the features based upon the mean and standard deviation of each column. \n",
    "# However, we do not want to accidentally use the testing data to find out the mean and std (this would be snooping)\n",
    "# to Make things easier, let's start by just using whatever was last stored in the variables:\n",
    "##    X_train , y_train , X_test, y_test (they were set in a for loop above)\n",
    "\n",
    "# scale attributes by the training set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train) # find scalings for each column that make this zero mean and unit std\n",
    "# the line of code above only looks at training data to get mean and std and we can use it \n",
    "# to transform new feature data\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) # apply those means and std to the test set (without snooping at the test set values)\n",
    "\n",
    "# train the model just as before\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.05, solver='liblinear') # get object, the 'C' value is less (can you guess why??)\n",
    "lr_clf.fit(X_train_scaled,y_train)  # train object\n",
    "\n",
    "y_hat = lr_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf )\n",
    "\n",
    "# sort these attributes and spit them out\n",
    "zip_vars = zip(lr_clf.coef_.T,oversampled.columns) # combine attributes\n",
    "zip_vars = sorted(zip_vars)\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0]) # now print them outv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4a5605",
   "metadata": {},
   "source": [
    "### Needs attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418afa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's make a pandas Series with the names and values, and plot them\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "weights = pd.Series(lr_clf.coef_[0],index=oversampled.columns)\n",
    "weights.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efcbd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# we want to normalize the features based upon the mean and standard deviation of each column. \n",
    "# However, we do not want to accidentally use the testing data to find out the mean and std (this would be snooping)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "# you can apply the StandardScaler function inside of the cross-validation loop \n",
    "#  but this requires the use of PipeLines in scikit. \n",
    "#  A pipeline can apply feature pre-processing and data fitting in one compact notation\n",
    "#  Here is an example!\n",
    "\n",
    "std_scl = StandardScaler()\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.05, solver='liblinear') \n",
    "\n",
    "# create the pipline\n",
    "piped_object = Pipeline([('scale', std_scl),  # do this\n",
    "                         ('logit_model', lr_clf)]) # and then do this\n",
    "\n",
    "weights = []\n",
    "# run the pipline cross validated\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object.split(X,y)):\n",
    "    piped_object.fit(X_new[train_indices],y[train_indices])  # train object\n",
    "    # it is a little odd getting trained objects from a  pipeline:\n",
    "    weights.append(piped_object.named_steps['logit_model'].coef_[0])\n",
    "    \n",
    "\n",
    "weights = np.array(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d64616c",
   "metadata": {},
   "source": [
    "## Needs Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b17d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "plotly.offline.init_notebook_mode() # run at the start of every notebook\n",
    "\n",
    "error_y=dict(\n",
    "            type='data',\n",
    "            array=np.std(weights,axis=0),\n",
    "            visible=True\n",
    "        )\n",
    "\n",
    "graph1 = {'x': oversampled.columns,\n",
    "          'y': np.mean(weights,axis=0),\n",
    "    'error_y':error_y,\n",
    "       'type': 'bar'}\n",
    "\n",
    "fig = dict()\n",
    "fig['data'] = [graph1]\n",
    "fig['layout'] = {'title': 'Logistic Regression Weights, with error bars'}\n",
    "\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e45886",
   "metadata": {},
   "source": [
    "### Needs Attention***  need to decide on the attributes for Xnew. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b727b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xnew = oversampled[['Year','WindGustSpeed','RainToday']].values\n",
    "\n",
    "weights = []\n",
    "# run the pipline corssvalidated\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object.split(Xnew,y)):\n",
    "    piped_object.fit(Xnew[train_indices],y[train_indices])  # train object\n",
    "    weights.append(piped_object.named_steps['logit_model'].coef_[0])\n",
    "    \n",
    "weights = np.array(weights)\n",
    "\n",
    "error_y=dict(\n",
    "            type='data',\n",
    "            array=np.std(weights,axis=0),\n",
    "            visible=True\n",
    "        )\n",
    "\n",
    "graph1 = {'x': ['Year','WindGustSpeed','RainToday'],\n",
    "          'y': np.mean(weights,axis=0),\n",
    "    'error_y':error_y,\n",
    "       'type': 'bar'}\n",
    "\n",
    "fig = dict()\n",
    "fig['data'] = [graph1]\n",
    "fig['layout'] = {'title': 'Logistic Regression Weights, with error bars'}\n",
    "\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e703154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime import lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca22bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM Using df_impute\n",
    "\n",
    "# okay, so run through the cross validation loop and set the training and testing variable for one single iteration\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9a3730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# lets investigate SVMs on the data and play with the parameters and kernels\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# train the model just as before\n",
    "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(X_train_scaled, y_train)  # train object\n",
    "\n",
    "y_hat = svm_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e789d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the support vectors\n",
    "print(svm_clf.support_vectors_.shape)\n",
    "print(svm_clf.support_.shape)\n",
    "print(svm_clf.n_support_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c682c53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svm_clf.coef_)\n",
    "weights = pd.Series(svm_clf.coef_[0],index=df_imputed.columns)\n",
    "weights.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3c0108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do some different analysis with the SVM and look at the instances that were chosen as support vectors\n",
    "\n",
    "# now lets look at the support for the vectors and see if we they are indicative of anything\n",
    "# grabe the rows that were selected as support vectors (these are usually instances that are hard to classify)\n",
    "\n",
    "# make a dataframe of the training data\n",
    "df_tested_on = oversampled.iloc[train_indices].copy() # saved from above, the indices chosen for training\n",
    "# now get the support vectors from the trained model\n",
    "df_support = oversampled.iloc[svm_clf.support_,:].copy()\n",
    "\n",
    "df_support['RainTomorrow'] = y[svm_clf.support_] # add back in the 'Survived' Column to the pandas dataframe\n",
    "oversampled['RainTomorrow'] = y # also add it back in for the original data\n",
    "df_support.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b8ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets see the statistics of these attributes\n",
    "from pandas.plotting import boxplot\n",
    "\n",
    "# group the original data and the support vectors\n",
    "df_grouped_support = df_support.groupby(['RainTomorrow'])\n",
    "df_grouped = oversampled.groupby(['RainTomorrow'])\n",
    "\n",
    "# plot KDE of Different variables\n",
    "vars_to_plot = ['Date','WindGustDir','RainToday','RainfallAmount']\n",
    "\n",
    "for v in vars_to_plot:\n",
    "    plt.figure(figsize=(10,4))\n",
    "    # plot support vector stats\n",
    "    plt.subplot(1,2,1)\n",
    "    ax = df_grouped_support[v].plot.kde() \n",
    "    plt.legend(['No','Yes'])\n",
    "    plt.title(v+' (Instances chosen as Support Vectors)')\n",
    "    \n",
    "    # plot original distributions\n",
    "    plt.subplot(1,2,2)\n",
    "    ax = df_grouped[v].plot.kde() \n",
    "    plt.legend(['No','Yes'])\n",
    "    plt.title(v+' (Original)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2de21e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
